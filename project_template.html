<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>284787</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="predict-bike-sharing-demand-with-autogluon-template" class="cell markdown" id="uD_epXNC3RH7">
<h1>Predict Bike Sharing Demand with AutoGluon Template</h1>
</section>
<section id="project-predict-bike-sharing-demand-with-autogluon" class="cell markdown" id="Wlib5LCo3RIB">
<h2>Project: Predict Bike Sharing Demand with AutoGluon</h2>
<p>This notebook is a template with each step that you need to complete for the project.</p>
<p>Please fill in your code where there are explicit <code>?</code> markers in the notebook. You are welcome to add more cells and code as you see fit.</p>
<p>Once you have completed all the code implementations, please export your notebook as a HTML file so the reviews can view your code. Make sure you have all outputs correctly outputted.</p>
<p><code>File-&gt; Export Notebook As... -&gt; Export Notebook as HTML</code></p>
<p>There is a writeup to complete as well after all code implememtation is done. Please answer all questions and attach the necessary tables and charts. You can complete the writeup in either markdown or PDF.</p>
<p>Completing the code template and writeup template will cover all of the rubric points for this project.</p>
<p>The rubric contains "Stand Out Suggestions" for enhancing the project beyond the minimum requirements. The stand out suggestions are optional. If you decide to pursue the "stand out suggestions", you can include the code in this notebook and also discuss the results in the writeup file.</p>
</section>
<section id="step-1-create-an-account-with-kaggle" class="cell markdown" id="hjVzPXOO3RIH">
<h2>Step 1: Create an account with Kaggle</h2>
</section>
<section id="create-kaggle-account-and-download-api-key" class="cell markdown" id="LWe71mze3RII">
<h3>Create Kaggle Account and download API key</h3>
<p>Below is example of steps to get the API username and key. Each student will have their own username and key.</p>
</section>
<div class="cell markdown" id="l8uQaJ4b3RII">
<ol>
<li>Open account settings. <img src="kaggle1.png" alt="kaggle1.png" /> <img src="kaggle2.png" alt="kaggle2.png" /></li>
<li>Scroll down to API and click Create New API Token. <img src="kaggle3.png" alt="kaggle3.png" /> <img src="kaggle4.png" alt="kaggle4.png" /></li>
<li>Open up <code>kaggle.json</code> and use the username and key. <img src="kaggle5.png" alt="kaggle5.png" /></li>
</ol>
</div>
<section id="step-2-download-the-kaggle-dataset-using-the-kaggle-python-library" class="cell markdown" id="kCeI-yXY3RIM">
<h2>Step 2: Download the Kaggle dataset using the kaggle python library</h2>
</section>
<section id="open-up-sagemaker-studio-and-use-starter-template" class="cell markdown" id="mmBnuAeL3RIN">
<h3>Open up Sagemaker Studio and use starter template</h3>
</section>
<div class="cell markdown" id="pfBbIS0W3RIO">
<ol>
<li>Notebook should be using a <code>ml.t3.medium</code> instance (2 vCPU + 4 GiB)</li>
<li>Notebook should be using kernal: <code>Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)</code></li>
</ol>
</div>
<section id="install-packages" class="cell markdown" id="om3_7mP63RIP">
<h3>Install packages</h3>
</section>
<div class="cell code" data-execution_count="1" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}" id="xZvNputu3RIR" data-outputId="961716e5-7023-4caa-f488-9d36adfc40bb">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U pip</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U setuptools wheel</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U <span class="st">&quot;mxnet&lt;2.0.0&quot;</span> bokeh<span class="op">==</span><span class="fl">2.0.1</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install autogluon <span class="op">--</span>no<span class="op">-</span>cache<span class="op">-</span><span class="bu">dir</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Without --no-cache-dir, smaller aws instances may have trouble installing</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)
Collecting setuptools
  Downloading setuptools-67.8.0-py3-none-any.whl (1.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 45.0 MB/s eta 0:00:00
ent already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.40.0)
Installing collected packages: setuptools
  Attempting uninstall: setuptools
    Found existing installation: setuptools 67.7.2
    Uninstalling setuptools-67.7.2:
      Successfully uninstalled setuptools-67.7.2
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
ipython 7.34.0 requires jedi&gt;=0.16, which is not installed.
Successfully installed setuptools-67.8.0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb3"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;pip_warning&quot;</span><span class="fu">:{</span><span class="dt">&quot;packages&quot;</span><span class="fu">:</span><span class="ot">[</span><span class="st">&quot;_distutils_hack&quot;</span><span class="ot">,</span><span class="st">&quot;pkg_resources&quot;</span><span class="ot">,</span><span class="st">&quot;setuptools&quot;</span><span class="ot">]</span><span class="fu">}}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting mxnet&lt;2.0.0
  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.1/49.1 MB 15.9 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 88.8 MB/s eta 0:00:00
etadata (setup.py) ... ent already satisfied: PyYAML&gt;=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (2.8.2)
Requirement already satisfied: Jinja2&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (3.1.2)
Requirement already satisfied: numpy&gt;=1.11.3 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (1.22.4)
Requirement already satisfied: pillow&gt;=4.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (8.4.0)
Requirement already satisfied: packaging&gt;=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (23.1)
Requirement already satisfied: tornado&gt;=5 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (6.3.1)
Requirement already satisfied: typing_extensions&gt;=3.7.4 in /usr/local/lib/python3.10/dist-packages (from bokeh==2.0.1) (4.5.0)
Requirement already satisfied: requests&lt;3,&gt;=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet&lt;2.0.0) (2.27.1)
Collecting graphviz&lt;0.9.0,&gt;=0.8.1 (from mxnet&lt;2.0.0)
  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2&gt;=2.7-&gt;bokeh==2.0.1) (2.1.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.1-&gt;bokeh==2.0.1) (1.16.0)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (1.26.15)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&lt;2.0.0) (3.4)
Building wheels for collected packages: bokeh
  Building wheel for bokeh (setup.py) ... e=bokeh-2.0.1-py3-none-any.whl size=9080019 sha256=a751b60c489895b5cf927e689a36255c55c3e243257ba29fed721d074ff9e3f2
  Stored in directory: /root/.cache/pip/wheels/be/b4/d8/7ce778fd6e637bea03a561223a77ba6649aff8168e3c613754
Successfully built bokeh
Installing collected packages: graphviz, mxnet, bokeh
  Attempting uninstall: graphviz
    Found existing installation: graphviz 0.20.1
    Uninstalling graphviz-0.20.1:
      Successfully uninstalled graphviz-0.20.1
  Attempting uninstall: bokeh
    Found existing installation: bokeh 2.4.3
    Uninstalling bokeh-2.4.3:
      Successfully uninstalled bokeh-2.4.3
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
panel 0.14.4 requires bokeh&lt;2.5.0,&gt;=2.4.0, but you have bokeh 2.0.1 which is incompatible.
Successfully installed bokeh-2.0.1 graphviz-0.8.4 mxnet-1.9.1
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting autogluon
  Downloading autogluon-0.7.0-py3-none-any.whl (9.7 kB)
Collecting autogluon.core[all]==0.7.0 (from autogluon)
  Downloading autogluon.core-0.7.0-py3-none-any.whl (218 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 218.3/218.3 kB 52.8 MB/s eta 0:00:00
 autogluon)
  Downloading autogluon.features-0.7.0-py3-none-any.whl (60 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.1/60.1 kB 295.9 MB/s eta 0:00:00
 autogluon)
  Downloading autogluon.tabular-0.7.0-py3-none-any.whl (292 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 292.2/292.2 kB 347.2 MB/s eta 0:00:00
ultimodal==0.7.0 (from autogluon)
  Downloading autogluon.multimodal-0.7.0-py3-none-any.whl (331 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 331.1/331.1 kB 355.1 MB/s eta 0:00:00
eseries[all]==0.7.0 (from autogluon)
  Downloading autogluon.timeseries-0.7.0-py3-none-any.whl (108 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 108.7/108.7 kB 320.9 MB/s eta 0:00:00
ent already satisfied: numpy&lt;1.27,&gt;=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.22.4)
Requirement already satisfied: scipy&lt;1.12,&gt;=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.10.1)
Requirement already satisfied: scikit-learn&lt;1.3,&gt;=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.2.2)
Collecting networkx&lt;3.0,&gt;=2.3 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 358.2 MB/s eta 0:00:00
ent already satisfied: pandas&lt;1.6,&gt;=1.4.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (1.5.3)
Requirement already satisfied: tqdm&lt;5,&gt;=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (4.65.0)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (2.27.1)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (3.7.1)
Collecting boto3&lt;2,&gt;=1.10 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading boto3-1.26.141-py3-none-any.whl (135 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 224.5 MB/s eta 0:00:00
mon==0.7.0 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading autogluon.common-0.7.0-py3-none-any.whl (45 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.0/45.0 kB 177.1 MB/s eta 0:00:00
ent already satisfied: hyperopt&lt;0.2.8,&gt;=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0-&gt;autogluon) (0.2.7)
Collecting ray[tune]&lt;2.3,&gt;=2.2 (from autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading ray-2.2.0-cp310-cp310-manylinux2014_x86_64.whl (57.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.4/57.4 MB 160.0 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 354.1 MB/s eta 0:00:00
a&lt;4.18,&gt;=4.14 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 kB 212.7 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading seqeval-1.2.2.tar.gz (43 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 248.6 MB/s eta 0:00:00
etadata (setup.py) ...  autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 72.9/72.9 kB 284.7 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.7/199.7 kB 336.7 MB/s eta 0:00:00
m&lt;0.7.0,&gt;=0.6.12 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading timm-0.6.13-py3-none-any.whl (549 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 549.1/549.1 kB 172.4 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 887.5/887.5 MB 100.4 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.2/24.2 MB 255.6 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading fairscale-0.4.13.tar.gz (266 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 266.3/266.3 kB 290.1 MB/s eta 0:00:00
ents to build wheel ... etadata (pyproject.toml) ... ent already satisfied: scikit-image&lt;0.20.0,&gt;=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.19.3)
Collecting pytorch-lightning&lt;1.10.0,&gt;=1.9.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 829.5/829.5 kB 415.7 MB/s eta 0:00:00
ent already satisfied: text-unidecode&lt;1.4,&gt;=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (1.3)
Collecting torchmetrics&lt;0.9.0,&gt;=0.8.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 409.8/409.8 kB 376.1 MB/s eta 0:00:00
ers&lt;4.27.0,&gt;=4.23.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 283.0 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)
Collecting omegaconf&lt;2.3.0,&gt;=2.1.1 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.3/79.3 kB 214.8 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 394.7 MB/s eta 0:00:00
etric-learning&lt;2.0,&gt;=1.3.0 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 112.2/112.2 kB 310.9 MB/s eta 0:00:00
 autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.5/410.5 kB 416.9 MB/s eta 0:00:00
ent already satisfied: nltk&lt;4.0.0,&gt;=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (3.8.1)
Collecting openmim&lt;0.4.0,&gt;0.1.5 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 51.3/51.3 kB 196.1 MB/s eta 0:00:00
ent already satisfied: defusedxml&lt;0.7.2,&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (0.7.1)
Requirement already satisfied: jinja2&lt;3.2,&gt;=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (3.1.2)
Requirement already satisfied: tensorboard&lt;3,&gt;=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0-&gt;autogluon) (2.12.2)
Collecting pytesseract&lt;0.3.11,&gt;=0.3.9 (from autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)
Collecting catboost&lt;1.2,&gt;=1.0 (from autogluon.tabular[all]==0.7.0-&gt;autogluon)
  Downloading catboost-1.1.1-cp310-none-manylinux1_x86_64.whl (76.6 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.6/76.6 MB 178.3 MB/s eta 0:00:00
ent already satisfied: lightgbm&lt;3.4,&gt;=3.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.3.5)
Requirement already satisfied: xgboost&lt;1.8,&gt;=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.7.5)
Requirement already satisfied: fastai&lt;2.8,&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.7.12)
Requirement already satisfied: joblib&lt;2,&gt;=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.2.0)
Requirement already satisfied: statsmodels&lt;0.14,&gt;=0.13.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.13.5)
Collecting gluonts&lt;0.13,&gt;=0.12.0 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading gluonts-0.12.8-py3-none-any.whl (1.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 375.6 MB/s eta 0:00:00
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.0/92.0 kB 332.1 MB/s eta 0:00:00
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading ujson-5.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 256.4 MB/s eta 0:00:00
e&lt;0.16,&gt;=0.14 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading sktime-0.15.1-py3-none-any.whl (16.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 169.3 MB/s eta 0:00:00
 autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.0/44.0 kB 178.1 MB/s eta 0:00:00
darima&lt;1.9,&gt;=1.8.2 (from autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading pmdarima-1.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 173.5 MB/s eta 0:00:00
ent already satisfied: psutil&lt;6,&gt;=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (5.9.5)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (67.8.0)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate&lt;0.17,&gt;=0.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (23.1)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate&lt;0.17,&gt;=0.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (6.0)
Collecting botocore&lt;1.30.0,&gt;=1.29.141 (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading botocore-1.29.141-py3-none-any.whl (10.8 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.8/10.8 MB 369.3 MB/s eta 0:00:00
espath&lt;2.0.0,&gt;=0.7.1 (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)
Collecting s3transfer&lt;0.7.0,&gt;=0.6.0 (from boto3&lt;2,&gt;=1.10-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 330.8 MB/s eta 0:00:00
ent already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.8.4)
Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (5.13.1)
Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.16.0)
Collecting datasets&gt;=2.0.0 (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 474.6/474.6 kB 327.7 MB/s eta 0:00:00
 evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading dill-0.3.6-py3-none-any.whl (110 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 330.6 MB/s eta 0:00:00
 evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.5/212.5 kB 342.8 MB/s eta 0:00:00
ultiprocess (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.3/134.3 kB 297.2 MB/s eta 0:00:00
ent already satisfied: fsspec[http]&gt;=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2023.4.0)
Collecting huggingface-hub&gt;=0.7.0 (from evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 224.5/224.5 kB 408.3 MB/s eta 0:00:00
 evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading responses-0.18.0-py3-none-any.whl (38 kB)
Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (23.1.2)
Requirement already satisfied: fastdownload&lt;2,&gt;=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.0.7)
Requirement already satisfied: fastcore&lt;1.6,&gt;=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.5.29)
Requirement already satisfied: fastprogress&gt;=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.3)
Requirement already satisfied: spacy&lt;4 in /usr/local/lib/python3.10/dist-packages (from fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.5.2)
Requirement already satisfied: pydantic~=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.10.7)
Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.12.0)
Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts&lt;0.13,&gt;=0.12.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (4.5.0)
Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.18.3)
Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.2.1)
Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt&lt;0.2.8,&gt;=0.2.7-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.10.9.7)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2&lt;3.2,&gt;=3.0.3-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.1.2)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema&lt;4.18,&gt;=4.14-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (23.1.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema&lt;4.18,&gt;=4.14-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.19.3)
Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm&lt;3.4,&gt;=3.3-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.40.0)
Requirement already satisfied: gdown&gt;=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.6.6)
Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk&lt;4.0.0,&gt;=3.4.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (8.1.3)
Requirement already satisfied: regex&gt;=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk&lt;4.0.0,&gt;=3.4.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2022.10.31)
Collecting antlr4-python3-runtime==4.9.* (from omegaconf&lt;2.3.0,&gt;=2.1.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 kB 300.0 MB/s eta 0:00:00
etadata (setup.py) ... a (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
Collecting model-index (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)
Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (13.3.4)
Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.8.10)
Requirement already satisfied: python-dateutil&gt;=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas&lt;1.6,&gt;=1.4.1-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas&lt;1.6,&gt;=1.4.1-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2022.7.1)
Requirement already satisfied: Cython!=0.29.18,&gt;=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima&lt;1.9,&gt;=1.8.2-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.29.34)
Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima&lt;1.9,&gt;=1.8.2-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.26.15)
Collecting lightning-utilities&gt;=0.6.0.post0 (from pytorch-lightning&lt;1.10.0,&gt;=1.9.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.12.0)
Requirement already satisfied: msgpack&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.5)
Requirement already satisfied: protobuf!=3.19.5,&gt;=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.20.3)
Collecting aiosignal (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Collecting frozenlist (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 149.6/149.6 kB 330.9 MB/s eta 0:00:00
 ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading virtualenv-20.23.0-py3-none-any.whl (3.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 371.0 MB/s eta 0:00:00
ent already satisfied: grpcio&gt;=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.54.0)
Collecting tensorboardX&gt;=1.9 (from ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 341.9 MB/s eta 0:00:00
ent already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.4)
Requirement already satisfied: imageio&gt;=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.25.1)
Requirement already satisfied: tifffile&gt;=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2023.4.12)
Requirement already satisfied: PyWavelets&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image&lt;0.20.0,&gt;=0.19.1-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.4.1)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn&lt;1.3,&gt;=1.0-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.1.0)
Collecting deprecated&gt;=1.2.13 (from sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon)
  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)
Requirement already satisfied: numba&gt;=0.55 in /usr/local/lib/python3.10/dist-packages (from sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.56.4)
Requirement already satisfied: patsy&gt;=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels&lt;0.14,&gt;=0.13.0-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.5.3)
Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.4.0)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.17.3)
Requirement already satisfied: google-auth-oauthlib&lt;1.1,&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.0.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.4.3)
Requirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.7.0)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.8.1)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.3.0)
Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 849.3/849.3 kB 437.2 MB/s eta 0:00:00
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 557.1/557.1 MB 276.1 MB/s eta 0:00:00
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 317.1/317.1 MB 285.7 MB/s eta 0:00:00
 torch&lt;1.14,&gt;=1.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.0/21.0 MB 354.0 MB/s eta 0:00:00
 torchmetrics&lt;0.9.0,&gt;=0.8.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)
Collecting tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 (from transformers&lt;4.27.0,&gt;=4.23.0-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 379.1 MB/s eta 0:00:00
ent already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.0.7)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (4.39.3)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.4.4)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.0.9)
Requirement already satisfied: pyarrow&gt;=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (9.0.0)
Collecting aiohttp (from datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 288.9 MB/s eta 0:00:00
ent already satisfied: wrapt&lt;2,&gt;=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated&gt;=1.2.13-&gt;sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (1.14.1)
Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown&gt;=4.0.0-&gt;nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.11.2)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (5.3.0)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.3.0)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (4.9)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (1.3.1)
Requirement already satisfied: llvmlite&lt;0.40,&gt;=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba&gt;=0.55-&gt;sktime&lt;0.16,&gt;=0.14-&gt;autogluon.timeseries[all]==0.7.0-&gt;autogluon) (0.39.1)
Requirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.0.12)
Requirement already satisfied: spacy-loggers&lt;2.0.0,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.4)
Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.0.9)
Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.0.7)
Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.0.8)
Requirement already satisfied: thinc&lt;8.2.0,&gt;=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (8.1.9)
Requirement already satisfied: wasabi&lt;1.2.0,&gt;=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (1.1.1)
Requirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.4.6)
Requirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (2.0.8)
Requirement already satisfied: typer&lt;0.8.0,&gt;=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.7.0)
Requirement already satisfied: pathy&gt;=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.10.1)
Requirement already satisfied: smart-open&lt;7.0.0,&gt;=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (6.3.0)
Requirement already satisfied: langcodes&lt;4.0.0,&gt;=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (3.3.0)
Collecting distlib&lt;1,&gt;=0.3.6 (from virtualenv&gt;=20.0.24-&gt;ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon)
  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 468.5/468.5 kB 390.0 MB/s eta 0:00:00
ent already satisfied: platformdirs&lt;4,&gt;=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv&gt;=20.0.24-&gt;ray[tune]&lt;2.3,&gt;=2.2-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (3.3.0)
Collecting ordered-set (from model-index-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)
Requirement already satisfied: tenacity&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly-&gt;catboost&lt;1.2,&gt;=1.0-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (8.2.2)
Requirement already satisfied: markdown-it-py&lt;3.0.0,&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.2.0)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.14.0)
Collecting multidict&lt;7.0,&gt;=4.5 (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 261.4 MB/s eta 0:00:00
eout&lt;5.0,&gt;=4.0.0a3 (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)
Collecting yarl&lt;2.0,&gt;=1.0 (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate&lt;0.4.0,&gt;=0.2.2-&gt;autogluon.multimodal==0.7.0-&gt;autogluon)
  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 271.7 MB/s eta 0:00:00
ent already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&lt;3.0.0,&gt;=2.2.0-&gt;rich-&gt;openmim&lt;0.4.0,&gt;0.1.5-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.1.2)
Requirement already satisfied: pyasn1&lt;0.6.0,&gt;=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (0.5.0)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;1.1,&gt;=0.5-&gt;tensorboard&lt;3,&gt;=2.9-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (3.2.2)
Requirement already satisfied: blis&lt;0.8.0,&gt;=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.2.0,&gt;=8.1.8-&gt;spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.7.9)
Requirement already satisfied: confection&lt;1.0.0,&gt;=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc&lt;8.2.0,&gt;=8.1.8-&gt;spacy&lt;4-&gt;fastai&lt;2.8,&gt;=2.3.1-&gt;autogluon.tabular[all]==0.7.0-&gt;autogluon) (0.0.4)
Requirement already satisfied: soupsieve&gt;1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4-&gt;gdown&gt;=4.0.0-&gt;nlpaug&lt;1.2.0,&gt;=1.1.10-&gt;autogluon.multimodal==0.7.0-&gt;autogluon) (2.4.1)
Requirement already satisfied: PySocks!=1.5.7,&gt;=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;autogluon.core[all]==0.7.0-&gt;autogluon) (1.7.1)
Building wheels for collected packages: fairscale, antlr4-python3-runtime, seqeval
  Building wheel for fairscale (pyproject.toml) ... e=fairscale-0.4.13-py3-none-any.whl size=332112 sha256=83f7b6a1d4116202f2e4696ad73929efbc94dcb14614d13f7291ee6cb522486d
  Stored in directory: /tmp/pip-ephem-wheel-cache-8ze5uyrl/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3
  Building wheel for antlr4-python3-runtime (setup.py) ... e: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=e0ef72b7bb34af4c72fd249d2d2c59f8350c6bc70627b071c97881601bc884da
  Stored in directory: /tmp/pip-ephem-wheel-cache-8ze5uyrl/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88
  Building wheel for seqeval (setup.py) ... e=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=ddf4c2933674a31feb9e27289ca4ddfdc0da852464bb268ec43b54a4ca7de017
  Stored in directory: /tmp/pip-ephem-wheel-cache-8ze5uyrl/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa
Successfully built fairscale antlr4-python3-runtime seqeval
Installing collected packages: tokenizers, sentencepiece, distlib, antlr4-python3-runtime, xxhash, virtualenv, ujson, tensorboardX, pyDeprecate, Pillow, ordered-set, omegaconf, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nptyping, networkx, multidict, lightning-utilities, jsonschema, jmespath, frozenlist, dill, deprecated, colorama, async-timeout, yarl, responses, pytesseract, nvidia-cudnn-cu11, multiprocess, model-index, huggingface-hub, botocore, aiosignal, transformers, torch, seqeval, s3transfer, ray, openmim, gluonts, catboost, aiohttp, torchvision, torchmetrics, statsforecast, sktime, pytorch-metric-learning, pmdarima, nlpaug, fairscale, boto3, accelerate, timm, tbats, pytorch-lightning, datasets, autogluon.common, evaluate, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon
  Attempting uninstall: Pillow
    Found existing installation: Pillow 8.4.0
    Uninstalling Pillow-8.4.0:
      Successfully uninstalled Pillow-8.4.0
  Attempting uninstall: networkx
    Found existing installation: networkx 3.1
    Uninstalling networkx-3.1:
      Successfully uninstalled networkx-3.1
  Attempting uninstall: jsonschema
    Found existing installation: jsonschema 4.3.3
    Uninstalling jsonschema-4.3.3:
      Successfully uninstalled jsonschema-4.3.3
  Attempting uninstall: torch
    Found existing installation: torch 2.0.1+cu118
    Uninstalling torch-2.0.1+cu118:
      Successfully uninstalled torch-2.0.1+cu118
  Attempting uninstall: torchvision
    Found existing installation: torchvision 0.15.2+cu118
    Uninstalling torchvision-0.15.2+cu118:
      Successfully uninstalled torchvision-0.15.2+cu118
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
panel 0.14.4 requires bokeh&lt;2.5.0,&gt;=2.4.0, but you have bokeh 2.0.1 which is incompatible.
torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.
torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.
torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.
Successfully installed Pillow-9.5.0 accelerate-0.16.0 aiohttp-3.8.4 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 async-timeout-4.0.2 autogluon-0.7.0 autogluon.common-0.7.0 autogluon.core-0.7.0 autogluon.features-0.7.0 autogluon.multimodal-0.7.0 autogluon.tabular-0.7.0 autogluon.timeseries-0.7.0 boto3-1.26.141 botocore-1.29.141 catboost-1.1.1 colorama-0.4.6 datasets-2.12.0 deprecated-1.2.13 dill-0.3.6 distlib-0.3.6 evaluate-0.3.0 fairscale-0.4.13 frozenlist-1.3.3 gluonts-0.12.8 huggingface-hub-0.14.1 jmespath-1.0.1 jsonschema-4.17.3 lightning-utilities-0.8.0 model-index-0.1.11 multidict-6.0.4 multiprocess-0.70.14 networkx-2.8.8 nlpaug-1.1.11 nptyping-2.4.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.2.3 openmim-0.3.7 ordered-set-4.1.0 pmdarima-1.8.5 pyDeprecate-0.3.2 pytesseract-0.3.10 pytorch-lightning-1.9.5 pytorch-metric-learning-1.7.3 ray-2.2.0 responses-0.18.0 s3transfer-0.6.1 sentencepiece-0.1.99 seqeval-1.2.2 sktime-0.15.1 statsforecast-1.4.0 tbats-1.1.3 tensorboardX-2.6 timm-0.6.13 tokenizers-0.13.3 torch-1.13.1 torchmetrics-0.8.2 torchvision-0.14.1 transformers-4.26.1 ujson-5.7.0 virtualenv-20.23.0 xxhash-3.2.0 yarl-1.9.2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb5"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;pip_warning&quot;</span><span class="fu">:{</span><span class="dt">&quot;packages&quot;</span><span class="fu">:</span><span class="ot">[</span><span class="st">&quot;PIL&quot;</span><span class="ot">,</span><span class="st">&quot;pydevd_plugins&quot;</span><span class="ot">]</span><span class="fu">}}</span></span></code></pre></div>
</div>
</div>
<section id="setup-kaggle-api-key" class="cell markdown" id="jXxOrArz3RIb">
<h3>Setup Kaggle API Key</h3>
</section>
<div class="cell code" data-execution_count="2" id="5gzdRb9Y3RId">
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create the .kaggle directory and an empty kaggle.json file</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>mkdir <span class="op">-</span>p <span class="op">/</span>root<span class="op">/</span>.kaggle</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>touch <span class="op">/</span>root<span class="op">/</span>.kaggle<span class="op">/</span>kaggle.json</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>chmod <span class="dv">600</span> <span class="op">/</span>root<span class="op">/</span>.kaggle<span class="op">/</span>kaggle.json</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="3" id="8DKWwkFy3RIe">
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fill in your user name and key from creating the kaggle account and API token file</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>kaggle_username <span class="op">=</span> <span class="st">&quot;akankshajoshii&quot;</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>kaggle_key <span class="op">=</span> <span class="st">&quot;3d47bffde37d04f0214795d46dd8c284&quot;</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Save API token the kaggle.json file</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">&quot;/root/.kaggle/kaggle.json&quot;</span>, <span class="st">&quot;w&quot;</span>) <span class="im">as</span> f:</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    f.write(json.dumps({<span class="st">&quot;username&quot;</span>: kaggle_username, <span class="st">&quot;key&quot;</span>: kaggle_key}))</span></code></pre></div>
</div>
<section id="download-and-explore-dataset" class="cell markdown" id="msUIPlJh3RJj">
<h3>Download and explore dataset</h3>
</section>
<section id="go-to-the-bike-sharing-demand-competition-and-agree-to-the-terms" class="cell markdown" id="4tGoCQhA3RJk">
<h3>Go to the bike sharing demand competition and agree to the terms</h3>
<p><img src="kaggle6.png" alt="kaggle6.png" /></p>
</section>
<div class="cell code" data-execution_count="4" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="xYbfk1iA3RJk" data-outputId="8bb985a5-27df-4ebe-833f-716d2eb95c54">
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the dataset, it will be in a .zip file so you&#39;ll need to unzip it as well.</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions download <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># If you already downloaded it you can use the -o command to overwrite the file</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>unzip <span class="op">-</span>o bike<span class="op">-</span>sharing<span class="op">-</span>demand.<span class="bu">zip</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Downloading bike-sharing-demand.zip to /content
100% 189k/189k [00:00&lt;00:00, 423kB/s]
100% 189k/189k [00:00&lt;00:00, 423kB/s]
Archive:  bike-sharing-demand.zip
  inflating: sampleSubmission.csv    
  inflating: test.csv                
  inflating: train.csv               
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="5" id="susvQ6023RJl">
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autogluon.tabular <span class="im">import</span> TabularPredictor</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="6" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}" id="UfBefrVn3RJl" data-outputId="6b1ae95b-9066-485f-dbd3-0c244c0f44d0">
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the train dataset in pandas by reading the csv</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the parsing of the datetime column so you can use some of the `dt` features in pandas later</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> pd.read_csv(<span class="st">&#39;train.csv&#39;</span>, parse_dates<span class="op">=</span>[<span class="st">&#39;datetime&#39;</span>])</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="6">

  <div id="df-231615ff-22e6-46b0-a6ce-5e6333bdb7fe">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>3</td>
      <td>13</td>
      <td>16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>8</td>
      <td>32</td>
      <td>40</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>5</td>
      <td>27</td>
      <td>32</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>3</td>
      <td>10</td>
      <td>13</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-231615ff-22e6-46b0-a6ce-5e6333bdb7fe')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-231615ff-22e6-46b0-a6ce-5e6333bdb7fe button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-231615ff-22e6-46b0-a6ce-5e6333bdb7fe');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="7" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="PZpPbCxs50UI" data-outputId="ec339d16-2757-459b-8896-fdf55f476cdb">
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>train.info()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 10886 entries, 0 to 10885
Data columns (total 12 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   datetime    10886 non-null  object 
 1   season      10886 non-null  int64  
 2   holiday     10886 non-null  int64  
 3   workingday  10886 non-null  int64  
 4   weather     10886 non-null  int64  
 5   temp        10886 non-null  float64
 6   atemp       10886 non-null  float64
 7   humidity    10886 non-null  int64  
 8   windspeed   10886 non-null  float64
 9   casual      10886 non-null  int64  
 10  registered  10886 non-null  int64  
 11  count       10886 non-null  int64  
dtypes: float64(3), int64(8), object(1)
memory usage: 1020.7+ KB
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="8" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:300}" id="s2uysQN13RJn" data-outputId="33ef4083-5900-4fce-fd64-7dfe48642de7">
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple output of the train dataset to view some of the min/max/varition of the dataset features.</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>train.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="8">

  <div id="df-6573dc83-88a8-4654-bffa-4907f4581d79">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.00000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.506614</td>
      <td>0.028569</td>
      <td>0.680875</td>
      <td>1.418427</td>
      <td>20.23086</td>
      <td>23.655084</td>
      <td>61.886460</td>
      <td>12.799395</td>
      <td>36.021955</td>
      <td>155.552177</td>
      <td>191.574132</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.116174</td>
      <td>0.166599</td>
      <td>0.466159</td>
      <td>0.633839</td>
      <td>7.79159</td>
      <td>8.474601</td>
      <td>19.245033</td>
      <td>8.164537</td>
      <td>49.960477</td>
      <td>151.039033</td>
      <td>181.144454</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.82000</td>
      <td>0.760000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>13.94000</td>
      <td>16.665000</td>
      <td>47.000000</td>
      <td>7.001500</td>
      <td>4.000000</td>
      <td>36.000000</td>
      <td>42.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>20.50000</td>
      <td>24.240000</td>
      <td>62.000000</td>
      <td>12.998000</td>
      <td>17.000000</td>
      <td>118.000000</td>
      <td>145.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>26.24000</td>
      <td>31.060000</td>
      <td>77.000000</td>
      <td>16.997900</td>
      <td>49.000000</td>
      <td>222.000000</td>
      <td>284.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
      <td>41.00000</td>
      <td>45.455000</td>
      <td>100.000000</td>
      <td>56.996900</td>
      <td>367.000000</td>
      <td>886.000000</td>
      <td>977.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-6573dc83-88a8-4654-bffa-4907f4581d79')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-6573dc83-88a8-4654-bffa-4907f4581d79 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-6573dc83-88a8-4654-bffa-4907f4581d79');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="9" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}" id="kCv_ncQ03RJu" data-outputId="82ede9db-d275-4780-ec17-fb48f4cce893">
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the test pandas dataframe in pandas by reading the csv, remember to parse the datetime!</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> pd.read_csv(<span class="st">&#39;test.csv&#39;</span>, parse_dates<span class="op">=</span>[<span class="st">&#39;datetime&#39;</span>])</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>test.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="9">

  <div id="df-fce6a095-e3c1-4b5b-89be-18dd21d62999">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>11.365</td>
      <td>56</td>
      <td>26.0027</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>13.635</td>
      <td>56</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>13.635</td>
      <td>56</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>12.880</td>
      <td>56</td>
      <td>11.0014</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>10.66</td>
      <td>12.880</td>
      <td>56</td>
      <td>11.0014</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-fce6a095-e3c1-4b5b-89be-18dd21d62999')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-fce6a095-e3c1-4b5b-89be-18dd21d62999 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-fce6a095-e3c1-4b5b-89be-18dd21d62999');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="10" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}" id="Bxo7cQ_S3RJv" data-outputId="e69fb087-9279-41f6-dd66-b350bed1627f">
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same thing as train and test dataset</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>submission <span class="op">=</span> pd.read_csv(<span class="st">&#39;sampleSubmission.csv&#39;</span>, parse_dates<span class="op">=</span>[<span class="st">&#39;datetime&#39;</span>])</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>submission.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="10">

  <div id="df-e6574018-65ba-4de6-999f-1cd6bf289efc">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-20 00:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-20 01:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-20 02:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-20 03:00:00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-20 04:00:00</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-e6574018-65ba-4de6-999f-1cd6bf289efc')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-e6574018-65ba-4de6-999f-1cd6bf289efc button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-e6574018-65ba-4de6-999f-1cd6bf289efc');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<section id="step-3-train-a-model-using-autogluons-tabular-prediction" class="cell markdown" id="steJNwKd3RJw">
<h2>Step 3: Train a model using AutoGluon’s Tabular Prediction</h2>
</section>
<div class="cell markdown" id="aAwHnsnb3RJx">
<p>Requirements:</p>
<ul>
<li>We are prediting <code>count</code>, so it is the label we are setting.</li>
<li>Ignore <code>casual</code> and <code>registered</code> columns as they are also not present in the test dataset.</li>
<li>Use the <code>root_mean_squared_error</code> as the metric to use for evaluation.</li>
<li>Set a time limit of 10 minutes (600 seconds).</li>
<li>Use the preset <code>best_quality</code> to focus on creating the best model.</li>
</ul>
</div>
<div class="cell code" data-execution_count="11" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:423}" id="pD0SRwZD6tBT" data-outputId="cec45248-9afc-409c-f37f-5f52daa31a13">
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> train.drop([<span class="st">&#39;casual&#39;</span>, <span class="st">&#39;registered&#39;</span>], axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>train</span></code></pre></div>
<div class="output execute_result" data-execution_count="11">

  <div id="df-7cd55e23-06c9-45c3-a4e9-4da2ae17f33e">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0000</td>
      <td>16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0000</td>
      <td>40</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0000</td>
      <td>32</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0000</td>
      <td>13</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10881</th>
      <td>2012-12-19 19:00:00</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>15.58</td>
      <td>19.695</td>
      <td>50</td>
      <td>26.0027</td>
      <td>336</td>
    </tr>
    <tr>
      <th>10882</th>
      <td>2012-12-19 20:00:00</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>14.76</td>
      <td>17.425</td>
      <td>57</td>
      <td>15.0013</td>
      <td>241</td>
    </tr>
    <tr>
      <th>10883</th>
      <td>2012-12-19 21:00:00</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>13.94</td>
      <td>15.910</td>
      <td>61</td>
      <td>15.0013</td>
      <td>168</td>
    </tr>
    <tr>
      <th>10884</th>
      <td>2012-12-19 22:00:00</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>13.94</td>
      <td>17.425</td>
      <td>61</td>
      <td>6.0032</td>
      <td>129</td>
    </tr>
    <tr>
      <th>10885</th>
      <td>2012-12-19 23:00:00</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>13.12</td>
      <td>16.665</td>
      <td>66</td>
      <td>8.9981</td>
      <td>88</td>
    </tr>
  </tbody>
</table>
<p>10886 rows × 10 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-7cd55e23-06c9-45c3-a4e9-4da2ae17f33e')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-7cd55e23-06c9-45c3-a4e9-4da2ae17f33e button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-7cd55e23-06c9-45c3-a4e9-4da2ae17f33e');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="12" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:300}" id="x2O7cY919c-P" data-outputId="c887e18f-ada6-4eea-b084-8e0fe025a780">
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>train.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="12">

  <div id="df-7163290b-dc40-4b5d-9eb6-95b419ced86f">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.00000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.506614</td>
      <td>0.028569</td>
      <td>0.680875</td>
      <td>1.418427</td>
      <td>20.23086</td>
      <td>23.655084</td>
      <td>61.886460</td>
      <td>12.799395</td>
      <td>191.574132</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.116174</td>
      <td>0.166599</td>
      <td>0.466159</td>
      <td>0.633839</td>
      <td>7.79159</td>
      <td>8.474601</td>
      <td>19.245033</td>
      <td>8.164537</td>
      <td>181.144454</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.82000</td>
      <td>0.760000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>13.94000</td>
      <td>16.665000</td>
      <td>47.000000</td>
      <td>7.001500</td>
      <td>42.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>20.50000</td>
      <td>24.240000</td>
      <td>62.000000</td>
      <td>12.998000</td>
      <td>145.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>26.24000</td>
      <td>31.060000</td>
      <td>77.000000</td>
      <td>16.997900</td>
      <td>284.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
      <td>41.00000</td>
      <td>45.455000</td>
      <td>100.000000</td>
      <td>56.996900</td>
      <td>977.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-7163290b-dc40-4b5d-9eb6-95b419ced86f')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-7163290b-dc40-4b5d-9eb6-95b419ced86f button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-7163290b-dc40-4b5d-9eb6-95b419ced86f');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="13" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="uUP8oMe63RJy" data-outputId="b87a3cdc-daed-4562-cbf6-a6e90dca66df">
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>predictor <span class="op">=</span> TabularPredictor(label <span class="op">=</span> <span class="st">&#39;count&#39;</span>, eval_metric <span class="op">=</span> <span class="st">&#39;root_mean_squared_error&#39;</span>, problem_type<span class="op">=</span><span class="st">&#39;regression&#39;</span>).fit(train, time_limit <span class="op">=</span> <span class="dv">600</span>, presets <span class="op">=</span> <span class="st">&#39;best_quality&#39;</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230526_172641/&quot;
Presets specified: [&#39;best_quality&#39;]
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230526_172641/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.11
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 9
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    11863.06 MB
	Train Data (Original)  Memory Usage: 1.52 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 2 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;float&#39;, [])                      : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                        : 5 | [&#39;season&#39;, &#39;holiday&#39;, &#39;workingday&#39;, &#39;weather&#39;, &#39;humidity&#39;]
		(&#39;object&#39;, [&#39;datetime_as_object&#39;]) : 1 | [&#39;datetime&#39;]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 3 | [&#39;season&#39;, &#39;weather&#39;, &#39;humidity&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.2s = Fit runtime
	9 features in original data used to generate 13 features in processed data.
	Train Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.19s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
Fitting 11 L1 models ...
Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.77s of the 599.8s of remaining time.
	-101.5462	 = Validation score   (-root_mean_squared_error)
	0.04s	 = Training   runtime
	0.06s	 = Validation runtime
Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.61s of the 599.64s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.04s	 = Training   runtime
	0.06s	 = Validation runtime
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 399.48s of the 599.51s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-131.4609	 = Validation score   (-root_mean_squared_error)
	92.5s	 = Training   runtime
	9.65s	 = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 294.06s of the 494.09s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-131.0542	 = Validation score   (-root_mean_squared_error)
	40.9s	 = Training   runtime
	2.09s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 248.78s of the 448.81s of remaining time.
	-116.5484	 = Validation score   (-root_mean_squared_error)
	12.16s	 = Training   runtime
	0.52s	 = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 235.31s of the 435.34s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-130.5545	 = Validation score   (-root_mean_squared_error)
	188.78s	 = Training   runtime
	0.28s	 = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 41.12s of the 241.15s of remaining time.
	-124.6007	 = Validation score   (-root_mean_squared_error)
	6.49s	 = Training   runtime
	0.47s	 = Validation runtime
Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 33.52s of the 233.55s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-140.5472	 = Validation score   (-root_mean_squared_error)
	55.15s	 = Training   runtime
	0.34s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 175.3s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.65s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 9 L2 models ...
Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 174.62s of the 174.6s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-60.4121	 = Validation score   (-root_mean_squared_error)
	59.23s	 = Training   runtime
	4.73s	 = Validation runtime
Fitting model: LightGBM_BAG_L2 ... Training model for up to 107.63s of the 107.62s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-55.0405	 = Validation score   (-root_mean_squared_error)
	31.13s	 = Training   runtime
	0.24s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 70.55s of the 70.53s of remaining time.
	-53.2602	 = Validation score   (-root_mean_squared_error)
	37.65s	 = Training   runtime
	0.87s	 = Validation runtime
Fitting model: CatBoost_BAG_L2 ... Training model for up to 31.18s of the 31.16s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-56.119	 = Validation score   (-root_mean_squared_error)
	38.72s	 = Training   runtime
	0.08s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -13.11s of remaining time.
	-52.9956	 = Validation score   (-root_mean_squared_error)
	0.32s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 613.47s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230526_172641/&quot;)
</code></pre>
</div>
</div>
<section id="review-autogluons-training-run-with-ranking-of-models-that-did-the-best" class="cell markdown" id="FnfdJPLU3RJz">
<h3>Review AutoGluon's training run with ranking of models that did the best.</h3>
</section>
<div class="cell code" data-execution_count="14" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="EU_b3x6N3RJ0" data-outputId="0f6d9fc5-9d98-4006-f3f0-f7b0d5142805">
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>predictor.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0      WeightedEnsemble_L3  -52.995605      19.403896  563.103294                0.000871           0.316895            3       True         14
1   RandomForestMSE_BAG_L2  -53.260153      14.352073  433.705120                0.871855          37.645430            2       True         12
2          LightGBM_BAG_L2  -55.040495      13.719171  427.187979                0.238952          31.128289            2       True         11
3          CatBoost_BAG_L2  -56.118954      13.561481  434.780816                0.081263          38.721126            2       True         13
4        LightGBMXT_BAG_L2  -60.412145      18.210955  455.291554                4.730737          59.231863            2       True         10
5    KNeighborsDist_BAG_L1  -84.125061       0.063986    0.039965                0.063986           0.039965            1       True          2
6      WeightedEnsemble_L2  -84.125061       0.064879    0.694214                0.000893           0.654249            2       True          9
7    KNeighborsUnif_BAG_L1 -101.546199       0.064122    0.040452                0.064122           0.040452            1       True          1
8   RandomForestMSE_BAG_L1 -116.548359       0.515029   12.161040                0.515029          12.161040            1       True          5
9     ExtraTreesMSE_BAG_L1 -124.600676       0.471233    6.488302                0.471233           6.488302            1       True          7
10         CatBoost_BAG_L1 -130.554534       0.283540  188.780502                0.283540         188.780502            1       True          6
11         LightGBM_BAG_L1 -131.054162       2.090477   40.898907                2.090477          40.898907            1       True          4
12       LightGBMXT_BAG_L1 -131.460909       9.649896   92.499580                9.649896          92.499580            1       True          3
13  NeuralNetFastAI_BAG_L1 -140.547192       0.341935   55.150941                0.341935          55.150941            1       True          8
Number of models trained: 14
Types of models trained:
{&#39;StackerEnsembleModel_LGB&#39;, &#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_NNFastAiTabular&#39;, &#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_CatBoost&#39;, &#39;StackerEnsembleModel_KNN&#39;, &#39;StackerEnsembleModel_XT&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 3 | [&#39;season&#39;, &#39;weather&#39;, &#39;humidity&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="14">
<pre><code>{&#39;model_types&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_XT&#39;,
  &#39;NeuralNetFastAI_BAG_L1&#39;: &#39;StackerEnsembleModel_NNFastAiTabular&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: -101.54619908446061,
  &#39;KNeighborsDist_BAG_L1&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L1&#39;: -131.46090891834504,
  &#39;LightGBM_BAG_L1&#39;: -131.054161598899,
  &#39;RandomForestMSE_BAG_L1&#39;: -116.54835939455667,
  &#39;CatBoost_BAG_L1&#39;: -130.55453379361106,
  &#39;ExtraTreesMSE_BAG_L1&#39;: -124.60067564699747,
  &#39;NeuralNetFastAI_BAG_L1&#39;: -140.54719208830616,
  &#39;WeightedEnsemble_L2&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L2&#39;: -60.41214494587225,
  &#39;LightGBM_BAG_L2&#39;: -55.04049547338523,
  &#39;RandomForestMSE_BAG_L2&#39;: -53.26015277857607,
  &#39;CatBoost_BAG_L2&#39;: -56.11895390874215,
  &#39;WeightedEnsemble_L3&#39;: -52.99560543830846},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_172641/models/KNeighborsUnif_BAG_L1/&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_172641/models/KNeighborsDist_BAG_L1/&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_172641/models/LightGBMXT_BAG_L1/&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_172641/models/LightGBM_BAG_L1/&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_172641/models/RandomForestMSE_BAG_L1/&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_172641/models/CatBoost_BAG_L1/&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_172641/models/ExtraTreesMSE_BAG_L1/&#39;,
  &#39;NeuralNetFastAI_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_172641/models/NeuralNetFastAI_BAG_L1/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230526_172641/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;AutogluonModels/ag-20230526_172641/models/LightGBMXT_BAG_L2/&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;AutogluonModels/ag-20230526_172641/models/LightGBM_BAG_L2/&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230526_172641/models/RandomForestMSE_BAG_L2/&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;AutogluonModels/ag-20230526_172641/models/CatBoost_BAG_L2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230526_172641/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.04045224189758301,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.039965152740478516,
  &#39;LightGBMXT_BAG_L1&#39;: 92.4995801448822,
  &#39;LightGBM_BAG_L1&#39;: 40.89890742301941,
  &#39;RandomForestMSE_BAG_L1&#39;: 12.16104006767273,
  &#39;CatBoost_BAG_L1&#39;: 188.78050231933594,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 6.488301992416382,
  &#39;NeuralNetFastAI_BAG_L1&#39;: 55.150941133499146,
  &#39;WeightedEnsemble_L2&#39;: 0.6542491912841797,
  &#39;LightGBMXT_BAG_L2&#39;: 59.231863498687744,
  &#39;LightGBM_BAG_L2&#39;: 31.128288984298706,
  &#39;RandomForestMSE_BAG_L2&#39;: 37.645429611206055,
  &#39;CatBoost_BAG_L2&#39;: 38.72112584114075,
  &#39;WeightedEnsemble_L3&#39;: 0.3168954849243164},
 &#39;model_pred_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.06412220001220703,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.06398606300354004,
  &#39;LightGBMXT_BAG_L1&#39;: 9.649895906448364,
  &#39;LightGBM_BAG_L1&#39;: 2.0904767513275146,
  &#39;RandomForestMSE_BAG_L1&#39;: 0.5150294303894043,
  &#39;CatBoost_BAG_L1&#39;: 0.2835395336151123,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 0.47123289108276367,
  &#39;NeuralNetFastAI_BAG_L1&#39;: 0.341935396194458,
  &#39;WeightedEnsemble_L2&#39;: 0.0008931159973144531,
  &#39;LightGBMXT_BAG_L2&#39;: 4.730736970901489,
  &#39;LightGBM_BAG_L2&#39;: 0.2389523983001709,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.8718545436859131,
  &#39;CatBoost_BAG_L2&#39;: 0.08126330375671387,
  &#39;WeightedEnsemble_L3&#39;: 0.0008709430694580078},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;KNeighborsDist_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;LightGBMXT_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;ExtraTreesMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;NeuralNetFastAI_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBMXT_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                      model   score_val  pred_time_val    fit_time  \
 0      WeightedEnsemble_L3  -52.995605      19.403896  563.103294   
 1   RandomForestMSE_BAG_L2  -53.260153      14.352073  433.705120   
 2          LightGBM_BAG_L2  -55.040495      13.719171  427.187979   
 3          CatBoost_BAG_L2  -56.118954      13.561481  434.780816   
 4        LightGBMXT_BAG_L2  -60.412145      18.210955  455.291554   
 5    KNeighborsDist_BAG_L1  -84.125061       0.063986    0.039965   
 6      WeightedEnsemble_L2  -84.125061       0.064879    0.694214   
 7    KNeighborsUnif_BAG_L1 -101.546199       0.064122    0.040452   
 8   RandomForestMSE_BAG_L1 -116.548359       0.515029   12.161040   
 9     ExtraTreesMSE_BAG_L1 -124.600676       0.471233    6.488302   
 10         CatBoost_BAG_L1 -130.554534       0.283540  188.780502   
 11         LightGBM_BAG_L1 -131.054162       2.090477   40.898907   
 12       LightGBMXT_BAG_L1 -131.460909       9.649896   92.499580   
 13  NeuralNetFastAI_BAG_L1 -140.547192       0.341935   55.150941   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.000871           0.316895            3       True   
 1                 0.871855          37.645430            2       True   
 2                 0.238952          31.128289            2       True   
 3                 0.081263          38.721126            2       True   
 4                 4.730737          59.231863            2       True   
 5                 0.063986           0.039965            1       True   
 6                 0.000893           0.654249            2       True   
 7                 0.064122           0.040452            1       True   
 8                 0.515029          12.161040            1       True   
 9                 0.471233           6.488302            1       True   
 10                0.283540         188.780502            1       True   
 11                2.090477          40.898907            1       True   
 12                9.649896          92.499580            1       True   
 13                0.341935          55.150941            1       True   
 
     fit_order  
 0          14  
 1          12  
 2          11  
 3          13  
 4          10  
 5           2  
 6           9  
 7           1  
 8           5  
 9           7  
 10          6  
 11          4  
 12          3  
 13          8  }</code></pre>
</div>
</div>
<section id="create-predictions-from-test-dataset" class="cell markdown" id="v6G2xe0v3RJ1">
<h3>Create predictions from test dataset</h3>
</section>
<div class="cell code" data-execution_count="15" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="VGelN59-3RJ2" data-outputId="a212329b-ff93-4477-8dcc-204d409ce505">
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> predictor.predict(test)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>predictions.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="15">
<pre><code>0    23.183226
1    43.166092
2    46.429569
3    49.010460
4    51.479942
Name: count, dtype: float32</code></pre>
</div>
</div>
<section id="note-kaggle-will-reject-the-submission-if-we-dont-set-everything-to-be--0" class="cell markdown" id="QAL8qGKk3RJ3">
<h4>NOTE: Kaggle will reject the submission if we don't set everything to be &gt; 0.</h4>
</section>
<div class="cell code" data-execution_count="16" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="MxRkbXYN3RJ6" data-outputId="e755c959-3c68-4fb4-be39-de3089541018">
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Describe the `predictions` series to see if there are any negative values</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>predictions.describe()</span></code></pre></div>
<div class="output execute_result" data-execution_count="16">
<pre><code>count    6493.000000
mean      100.501877
std        89.911583
min         3.358993
25%        20.032387
50%        63.981178
75%       167.354523
max       363.312531
Name: count, dtype: float64</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="17" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="lmT-F90s3RJ9" data-outputId="d178e361-9f94-47ff-8503-2e3c7699c84c">
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How many negative values do we have?</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>predictions[predictions<span class="op">&lt;</span><span class="dv">0</span>].count()</span></code></pre></div>
<div class="output execute_result" data-execution_count="17">
<pre><code>0</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="18" id="xOPUyCUR3RJ-">
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set them to zero</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>predictions[predictions <span class="op">&lt;</span> <span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
</div>
<section id="set-predictions-to-submission-dataframe-save-and-submit" class="cell markdown" id="PCSOHl-F3RJ_">
<h3>Set predictions to submission dataframe, save, and submit</h3>
</section>
<div class="cell code" data-execution_count="19" id="HfFwjogo3RJ_">
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>submission[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> predictions</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>submission.to_csv(<span class="st">&quot;submission.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="20" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="5Uw1U8FC3RKA" data-outputId="f701e57d-410e-4afd-cdc7-149efc7238e6">
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission.csv <span class="op">-</span>m <span class="st">&quot;first raw submission&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 188k/188k [00:02&lt;00:00, 93.9kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<section id="view-submission-via-the-command-line-or-in-the-web-browser-under-the-competitions-page---my-submissions" class="cell markdown" id="HijGfQ6q3RKB">
<h4>View submission via the command line or in the web browser under the competition's page - <code>My Submissions</code></h4>
</section>
<div class="cell code" data-execution_count="21" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="xxHztIBZ3RKB" data-outputId="409f9ea1-35f0-4c12-b11c-8db14dec606f">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission.csv               2023-05-26 17:37:48  first raw submission               complete  1.80114      1.80114       
submission_new_hpo.csv       2023-05-19 13:19:59  new features with hyperparameters  complete  0.61717      0.61717       
submission_new_features.csv  2023-05-19 12:57:37  new features                       complete  0.66046      0.66046       
submission.csv               2023-05-19 12:37:12  first raw submission               complete  1.79958      1.79958       
</code></pre>
</div>
</div>
<section id="initial-score-of-180114" class="cell markdown" id="-mff-ARz3RKB">
<h4>Initial score of 1.80114</h4>
</section>
<section id="step-4-exploratory-data-analysis-and-creating-an-additional-feature" class="cell markdown" id="WkUILc5t3RKC">
<h2>Step 4: Exploratory Data Analysis and Creating an additional feature</h2>
<ul>
<li>Any additional feature will do, but a great suggestion would be to separate out the datetime into hour, day, or month parts.</li>
</ul>
</section>
<div class="cell code" data-execution_count="22" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}" id="WsNqG2Zf3RK0" data-outputId="731a5d08-fb86-4f70-eb41-02791b3c2e80">
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a histogram of all features to show the distribution of each one relative to the data. This is part of the exploritory data analysis</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>train.hist(figsize<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">20</span>))</span></code></pre></div>
<div class="output execute_result" data-execution_count="22">
<pre><code>array([[&lt;Axes: title={&#39;center&#39;: &#39;season&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;holiday&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;workingday&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;weather&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;temp&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;atemp&#39;}&gt;],
       [&lt;Axes: title={&#39;center&#39;: &#39;humidity&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;windspeed&#39;}&gt;,
        &lt;Axes: title={&#39;center&#39;: &#39;count&#39;}&gt;]], dtype=object)</code></pre>
</div>
<div class="output display_data">
<p><img src="9deb9eea552106bb17f39eb23780e5351779b644.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="26" id="bJOL5Hyb3RK1">
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a new feature</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;datetime&#39;</span>] <span class="op">=</span> pd.to_datetime(train[<span class="st">&#39;datetime&#39;</span>])</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;datetime&#39;</span>] <span class="op">=</span> pd.to_datetime(test[<span class="st">&#39;datetime&#39;</span>])</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;month&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.month</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;day&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.day</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;hour&#39;</span>] <span class="op">=</span> train[<span class="st">&#39;datetime&#39;</span>].dt.hour</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;month&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.month</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;day&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.day</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&#39;hour&#39;</span>] <span class="op">=</span> test[<span class="st">&#39;datetime&#39;</span>].dt.hour</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="27" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:423}" id="8vUk87BVBk0p" data-outputId="6914eff5-e828-455d-c242-115974f799bf">
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>train</span></code></pre></div>
<div class="output execute_result" data-execution_count="27">

  <div id="df-076652f6-d920-4092-9518-5050cf0f9ce8">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>count</th>
      <th>month</th>
      <th>day</th>
      <th>hour</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0000</td>
      <td>16</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0000</td>
      <td>40</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0000</td>
      <td>32</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0000</td>
      <td>13</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0000</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10881</th>
      <td>2012-12-19 19:00:00</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>15.58</td>
      <td>19.695</td>
      <td>50</td>
      <td>26.0027</td>
      <td>336</td>
      <td>12</td>
      <td>19</td>
      <td>19</td>
    </tr>
    <tr>
      <th>10882</th>
      <td>2012-12-19 20:00:00</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>14.76</td>
      <td>17.425</td>
      <td>57</td>
      <td>15.0013</td>
      <td>241</td>
      <td>12</td>
      <td>19</td>
      <td>20</td>
    </tr>
    <tr>
      <th>10883</th>
      <td>2012-12-19 21:00:00</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>13.94</td>
      <td>15.910</td>
      <td>61</td>
      <td>15.0013</td>
      <td>168</td>
      <td>12</td>
      <td>19</td>
      <td>21</td>
    </tr>
    <tr>
      <th>10884</th>
      <td>2012-12-19 22:00:00</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>13.94</td>
      <td>17.425</td>
      <td>61</td>
      <td>6.0032</td>
      <td>129</td>
      <td>12</td>
      <td>19</td>
      <td>22</td>
    </tr>
    <tr>
      <th>10885</th>
      <td>2012-12-19 23:00:00</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>13.12</td>
      <td>16.665</td>
      <td>66</td>
      <td>8.9981</td>
      <td>88</td>
      <td>12</td>
      <td>19</td>
      <td>23</td>
    </tr>
  </tbody>
</table>
<p>10886 rows × 13 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-076652f6-d920-4092-9518-5050cf0f9ce8')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-076652f6-d920-4092-9518-5050cf0f9ce8 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-076652f6-d920-4092-9518-5050cf0f9ce8');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<section id="make-category-types-for-these-so-models-know-they-are-not-just-numbers" class="cell markdown" id="8NdXzxSV3RK2">
<h2>Make category types for these so models know they are not just numbers</h2>
<ul>
<li>AutoGluon originally sees these as ints, but in reality they are int representations of a category.</li>
<li>Setting the dtype to category will classify these as categories in AutoGluon.</li>
</ul>
</section>
<div class="cell code" data-execution_count="28" id="y91-Ttcq3RK3">
<div class="sourceCode" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&quot;season&quot;</span>] <span class="op">=</span> train[<span class="st">&#39;season&#39;</span>].astype(<span class="st">&#39;category&#39;</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&quot;weather&quot;</span>] <span class="op">=</span> train[<span class="st">&#39;weather&#39;</span>].astype(<span class="st">&#39;category&#39;</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&quot;season&quot;</span>] <span class="op">=</span> test[<span class="st">&#39;season&#39;</span>].astype(<span class="st">&#39;category&#39;</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>test[<span class="st">&quot;weather&quot;</span>] <span class="op">=</span> test[<span class="st">&#39;weather&#39;</span>].astype(<span class="st">&#39;category&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="29" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}" id="5Y5zYyVK3RK4" data-outputId="f3f8f5e4-6783-4c4c-a86c-026b10faeb92">
<div class="sourceCode" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View are new feature</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>train.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="29">

  <div id="df-1716b446-0d44-49d4-ac43-98a4b0f018ed">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>count</th>
      <th>month</th>
      <th>day</th>
      <th>hour</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>16</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>40</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>32</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>13</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-1716b446-0d44-49d4-ac43-98a4b0f018ed')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-1716b446-0d44-49d4-ac43-98a4b0f018ed button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-1716b446-0d44-49d4-ac43-98a4b0f018ed');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
<div class="cell code" data-execution_count="30" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}" id="7hCLY-gd3RK-" data-outputId="d03c2bb9-3031-422e-eff9-41ab61441fc4">
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View histogram of all features again now with the hour feature</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>train.hist(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">20</span>))<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img src="6239aae21a569552de13170d08dc982efbe3de44.png" /></p>
</div>
</div>
<section id="step-5-rerun-the-model-with-the-same-settings-as-before-just-with-more-features" class="cell markdown" id="Yo_PzftT3RLA">
<h2>Step 5: Rerun the model with the same settings as before, just with more features</h2>
</section>
<div class="cell code" data-execution_count="31" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="185sFiQ23RLB" data-outputId="8d85368f-8f1c-47a7-8595-87be7538c085">
<div class="sourceCode" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>predictor_new_features <span class="op">=</span> TabularPredictor(label <span class="op">=</span> <span class="st">&#39;count&#39;</span>, eval_metric <span class="op">=</span> <span class="st">&#39;root_mean_squared_error&#39;</span>, problem_type<span class="op">=</span><span class="st">&#39;regression&#39;</span>).fit(train, presets <span class="op">=</span> <span class="st">&#39;best_quality&#39;</span>, time_limit <span class="op">=</span> <span class="dv">600</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230526_174030/&quot;
Presets specified: [&#39;best_quality&#39;]
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230526_174030/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.11
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 12
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    10884.37 MB
	Train Data (Original)  Memory Usage: 0.89 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 2 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 6 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, ...]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.2s = Fit runtime
	12 features in original data used to generate 16 features in processed data.
	Train Data (Processed) Memory Usage: 1.09 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.19s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
Fitting 11 L1 models ...
Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.77s of the 599.8s of remaining time.
	-101.5462	 = Validation score   (-root_mean_squared_error)
	0.06s	 = Training   runtime
	0.08s	 = Validation runtime
Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 399.59s of the 599.62s of remaining time.
	-84.1251	 = Validation score   (-root_mean_squared_error)
	0.06s	 = Training   runtime
	0.07s	 = Validation runtime
Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 399.42s of the 599.45s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-34.361	 = Validation score   (-root_mean_squared_error)
	116.44s	 = Training   runtime
	14.98s	 = Validation runtime
Fitting model: LightGBM_BAG_L1 ... Training model for up to 272.64s of the 472.67s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-33.9169	 = Validation score   (-root_mean_squared_error)
	56.2s	 = Training   runtime
	3.66s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 211.44s of the 411.47s of remaining time.
	-38.3895	 = Validation score   (-root_mean_squared_error)
	18.12s	 = Training   runtime
	0.53s	 = Validation runtime
Fitting model: CatBoost_BAG_L1 ... Training model for up to 192.15s of the 392.18s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-34.2948	 = Validation score   (-root_mean_squared_error)
	167.86s	 = Training   runtime
	0.52s	 = Validation runtime
Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 20.38s of the 220.41s of remaining time.
	-38.3965	 = Validation score   (-root_mean_squared_error)
	9.58s	 = Training   runtime
	0.53s	 = Validation runtime
Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 9.01s of the 209.04s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-129.4433	 = Validation score   (-root_mean_squared_error)
	41.4s	 = Training   runtime
	1.63s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 164.53s of remaining time.
	-32.1267	 = Validation score   (-root_mean_squared_error)
	0.68s	 = Training   runtime
	0.0s	 = Validation runtime
Fitting 9 L2 models ...
Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 163.8s of the 163.78s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-31.2723	 = Validation score   (-root_mean_squared_error)
	39.78s	 = Training   runtime
	1.59s	 = Validation runtime
Fitting model: LightGBM_BAG_L2 ... Training model for up to 119.37s of the 119.35s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-30.6285	 = Validation score   (-root_mean_squared_error)
	29.01s	 = Training   runtime
	0.29s	 = Validation runtime
Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 85.47s of the 85.46s of remaining time.
	-31.6268	 = Validation score   (-root_mean_squared_error)
	42.76s	 = Training   runtime
	0.91s	 = Validation runtime
Fitting model: CatBoost_BAG_L2 ... Training model for up to 41.3s of the 41.28s of remaining time.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	-31.3169	 = Validation score   (-root_mean_squared_error)
	47.78s	 = Training   runtime
	0.16s	 = Validation runtime
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -14.26s of remaining time.
	-30.3981	 = Validation score   (-root_mean_squared_error)
	0.32s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 614.62s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230526_174030/&quot;)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="32" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="RsaPzRFh3RLC" data-outputId="c37bdd01-4016-469d-a535-eebe227b35eb">
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>predictor_new_features.fit_summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0      WeightedEnsemble_L3  -30.398147      24.945186  569.369047                0.000830           0.322837            3       True         14
1          LightGBM_BAG_L2  -30.628473      22.280586  438.723646                0.290378          29.009886            2       True         11
2        LightGBMXT_BAG_L2  -31.272253      23.579514  449.489717                1.589307          39.775957            2       True         10
3          CatBoost_BAG_L2  -31.316930      22.154348  457.497493                0.164140          47.783733            2       True         13
4   RandomForestMSE_BAG_L2  -31.626800      22.900531  452.476635                0.910323          42.762874            2       True         12
5      WeightedEnsemble_L2  -32.126711      19.754177  359.357472                0.000871           0.682081            2       True          9
6          LightGBM_BAG_L1  -33.916921       3.657290   56.198758                3.657290          56.198758            1       True          4
7          CatBoost_BAG_L1  -34.294757       0.516047  167.859084                0.516047         167.859084            1       True          6
8        LightGBMXT_BAG_L1  -34.360985      14.981102  116.444032               14.981102         116.444032            1       True          3
9   RandomForestMSE_BAG_L1  -38.389473       0.529016   18.115259                0.529016          18.115259            1       True          5
10    ExtraTreesMSE_BAG_L1  -38.396508       0.526744    9.581257                0.526744           9.581257            1       True          7
11   KNeighborsDist_BAG_L1  -84.125061       0.069852    0.058257                0.069852           0.058257            1       True          2
12   KNeighborsUnif_BAG_L1 -101.546199       0.078791    0.061529                0.078791           0.061529            1       True          1
13  NeuralNetFastAI_BAG_L1 -129.443307       1.631366   41.395583                1.631366          41.395583            1       True          8
Number of models trained: 14
Types of models trained:
{&#39;StackerEnsembleModel_LGB&#39;, &#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_NNFastAiTabular&#39;, &#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_CatBoost&#39;, &#39;StackerEnsembleModel_KNN&#39;, &#39;StackerEnsembleModel_XT&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="32">
<pre><code>{&#39;model_types&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;StackerEnsembleModel_KNN&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;StackerEnsembleModel_XT&#39;,
  &#39;NeuralNetFastAI_BAG_L1&#39;: &#39;StackerEnsembleModel_NNFastAiTabular&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;StackerEnsembleModel_RF&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;StackerEnsembleModel_CatBoost&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: -101.54619908446061,
  &#39;KNeighborsDist_BAG_L1&#39;: -84.12506123181602,
  &#39;LightGBMXT_BAG_L1&#39;: -34.36098453963965,
  &#39;LightGBM_BAG_L1&#39;: -33.91692104371548,
  &#39;RandomForestMSE_BAG_L1&#39;: -38.389473372037294,
  &#39;CatBoost_BAG_L1&#39;: -34.294756801963594,
  &#39;ExtraTreesMSE_BAG_L1&#39;: -38.39650776470448,
  &#39;NeuralNetFastAI_BAG_L1&#39;: -129.44330684736434,
  &#39;WeightedEnsemble_L2&#39;: -32.126710715119025,
  &#39;LightGBMXT_BAG_L2&#39;: -31.272253265842345,
  &#39;LightGBM_BAG_L2&#39;: -30.628472511571708,
  &#39;RandomForestMSE_BAG_L2&#39;: -31.626800047411727,
  &#39;CatBoost_BAG_L2&#39;: -31.31692998834423,
  &#39;WeightedEnsemble_L3&#39;: -30.398147151853184},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_174030/models/KNeighborsUnif_BAG_L1/&#39;,
  &#39;KNeighborsDist_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_174030/models/KNeighborsDist_BAG_L1/&#39;,
  &#39;LightGBMXT_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_174030/models/LightGBMXT_BAG_L1/&#39;,
  &#39;LightGBM_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_174030/models/LightGBM_BAG_L1/&#39;,
  &#39;RandomForestMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_174030/models/RandomForestMSE_BAG_L1/&#39;,
  &#39;CatBoost_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_174030/models/CatBoost_BAG_L1/&#39;,
  &#39;ExtraTreesMSE_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_174030/models/ExtraTreesMSE_BAG_L1/&#39;,
  &#39;NeuralNetFastAI_BAG_L1&#39;: &#39;AutogluonModels/ag-20230526_174030/models/NeuralNetFastAI_BAG_L1/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230526_174030/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBMXT_BAG_L2&#39;: &#39;AutogluonModels/ag-20230526_174030/models/LightGBMXT_BAG_L2/&#39;,
  &#39;LightGBM_BAG_L2&#39;: &#39;AutogluonModels/ag-20230526_174030/models/LightGBM_BAG_L2/&#39;,
  &#39;RandomForestMSE_BAG_L2&#39;: &#39;AutogluonModels/ag-20230526_174030/models/RandomForestMSE_BAG_L2/&#39;,
  &#39;CatBoost_BAG_L2&#39;: &#39;AutogluonModels/ag-20230526_174030/models/CatBoost_BAG_L2/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230526_174030/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.06152915954589844,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.058257341384887695,
  &#39;LightGBMXT_BAG_L1&#39;: 116.44403219223022,
  &#39;LightGBM_BAG_L1&#39;: 56.198758125305176,
  &#39;RandomForestMSE_BAG_L1&#39;: 18.115259170532227,
  &#39;CatBoost_BAG_L1&#39;: 167.85908436775208,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 9.581256866455078,
  &#39;NeuralNetFastAI_BAG_L1&#39;: 41.395583152770996,
  &#39;WeightedEnsemble_L2&#39;: 0.6820812225341797,
  &#39;LightGBMXT_BAG_L2&#39;: 39.77595663070679,
  &#39;LightGBM_BAG_L2&#39;: 29.009886026382446,
  &#39;RandomForestMSE_BAG_L2&#39;: 42.762874364852905,
  &#39;CatBoost_BAG_L2&#39;: 47.783732652664185,
  &#39;WeightedEnsemble_L3&#39;: 0.32283663749694824},
 &#39;model_pred_times&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: 0.07879114151000977,
  &#39;KNeighborsDist_BAG_L1&#39;: 0.06985187530517578,
  &#39;LightGBMXT_BAG_L1&#39;: 14.981101751327515,
  &#39;LightGBM_BAG_L1&#39;: 3.657289505004883,
  &#39;RandomForestMSE_BAG_L1&#39;: 0.5290157794952393,
  &#39;CatBoost_BAG_L1&#39;: 0.5160470008850098,
  &#39;ExtraTreesMSE_BAG_L1&#39;: 0.5267441272735596,
  &#39;NeuralNetFastAI_BAG_L1&#39;: 1.631366491317749,
  &#39;WeightedEnsemble_L2&#39;: 0.0008707046508789062,
  &#39;LightGBMXT_BAG_L2&#39;: 1.5893065929412842,
  &#39;LightGBM_BAG_L2&#39;: 0.2903780937194824,
  &#39;RandomForestMSE_BAG_L2&#39;: 0.9103231430053711,
  &#39;CatBoost_BAG_L2&#39;: 0.1641402244567871,
  &#39;WeightedEnsemble_L3&#39;: 0.0008301734924316406},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;KNeighborsUnif_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;KNeighborsDist_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;LightGBMXT_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;ExtraTreesMSE_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;NeuralNetFastAI_BAG_L1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBMXT_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;RandomForestMSE_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True,
   &#39;use_child_oof&#39;: True},
  &#39;CatBoost_BAG_L2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                      model   score_val  pred_time_val    fit_time  \
 0      WeightedEnsemble_L3  -30.398147      24.945186  569.369047   
 1          LightGBM_BAG_L2  -30.628473      22.280586  438.723646   
 2        LightGBMXT_BAG_L2  -31.272253      23.579514  449.489717   
 3          CatBoost_BAG_L2  -31.316930      22.154348  457.497493   
 4   RandomForestMSE_BAG_L2  -31.626800      22.900531  452.476635   
 5      WeightedEnsemble_L2  -32.126711      19.754177  359.357472   
 6          LightGBM_BAG_L1  -33.916921       3.657290   56.198758   
 7          CatBoost_BAG_L1  -34.294757       0.516047  167.859084   
 8        LightGBMXT_BAG_L1  -34.360985      14.981102  116.444032   
 9   RandomForestMSE_BAG_L1  -38.389473       0.529016   18.115259   
 10    ExtraTreesMSE_BAG_L1  -38.396508       0.526744    9.581257   
 11   KNeighborsDist_BAG_L1  -84.125061       0.069852    0.058257   
 12   KNeighborsUnif_BAG_L1 -101.546199       0.078791    0.061529   
 13  NeuralNetFastAI_BAG_L1 -129.443307       1.631366   41.395583   
 
     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                 0.000830           0.322837            3       True   
 1                 0.290378          29.009886            2       True   
 2                 1.589307          39.775957            2       True   
 3                 0.164140          47.783733            2       True   
 4                 0.910323          42.762874            2       True   
 5                 0.000871           0.682081            2       True   
 6                 3.657290          56.198758            1       True   
 7                 0.516047         167.859084            1       True   
 8                14.981102         116.444032            1       True   
 9                 0.529016          18.115259            1       True   
 10                0.526744           9.581257            1       True   
 11                0.069852           0.058257            1       True   
 12                0.078791           0.061529            1       True   
 13                1.631366          41.395583            1       True   
 
     fit_order  
 0          14  
 1          11  
 2          10  
 3          13  
 4          12  
 5           9  
 6           4  
 7           6  
 8           3  
 9           5  
 10          7  
 11          2  
 12          1  
 13          8  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="33" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="X6VcTcEk3RLD" data-outputId="6904f4ba-a7fd-488d-890c-7b1645526090">
<div class="sourceCode" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember to set all negative values to zero</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> predictor_new_features.predict(test)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>predictions[predictions <span class="op">&lt;</span> <span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>predictions</span></code></pre></div>
<div class="output execute_result" data-execution_count="33">
<pre><code>0        15.439933
1        11.133771
2        10.423406
3         9.252806
4         8.288759
           ...    
6488    305.724426
6489    212.114929
6490    154.414124
6491    110.863480
6492     71.764145
Name: count, Length: 6493, dtype: float32</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="34" id="leDCgQv1FHzJ">
<div class="sourceCode" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>touch submission_new_features.csv</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="35" id="MiJEv4wX3RLE">
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same submitting predictions</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>submission_new_features <span class="op">=</span> submission</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>submission_new_features[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> predictions</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>submission_new_features.to_csv(<span class="st">&quot;submission_new_features.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="36" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="EIbuV5dN3RLF" data-outputId="9d7e2dc8-45c9-434f-f3af-317121650e4e">
<div class="sourceCode" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission_new_features.csv <span class="op">-</span>m <span class="st">&quot;new features&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 188k/188k [00:04&lt;00:00, 48.0kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="37" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="yIvic69k3RLG" data-outputId="504125d4-121d-46c4-cd89-b1129a863dc9">
<div class="sourceCode" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission_new_features.csv  2023-05-26 17:51:54  new features                       complete  0.62685      0.62685       
submission.csv               2023-05-26 17:37:48  first raw submission               complete  1.80114      1.80114       
submission_new_hpo.csv       2023-05-19 13:19:59  new features with hyperparameters  complete  0.61717      0.61717       
submission_new_features.csv  2023-05-19 12:57:37  new features                       complete  0.66046      0.66046       
</code></pre>
</div>
</div>
<section id="new-score-of-062685" class="cell markdown" id="Lht0kDO83RLG">
<h4>New Score of 0.62685</h4>
</section>
<section id="step-6-hyper-parameter-optimization" class="cell markdown" id="QrgXhUPF3RLH">
<h2>Step 6: Hyper parameter optimization</h2>
<ul>
<li>There are many options for hyper parameter optimization.</li>
<li>Options are to change the AutoGluon higher level parameters or the individual model hyperparameters.</li>
<li>The hyperparameters of the models themselves that are in AutoGluon. Those need the <code>hyperparameter</code> and <code>hyperparameter_tune_kwargs</code> arguments.</li>
</ul>
</section>
<div class="cell code" data-execution_count="49" id="3NGp8i7kNGd-">
<div class="sourceCode" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autogluon.tabular.models.lgb.hyperparameters.parameters <span class="im">as</span> pm</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autogluon.core <span class="im">as</span> ag</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>nn_options <span class="op">=</span> {  <span class="st">&#39;dropout_prob&#39;</span>: ag.space.Real(<span class="fl">0.0</span>, <span class="fl">0.5</span>, default<span class="op">=</span><span class="fl">0.1</span>,)}</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>gbm_options <span class="op">=</span> {  <span class="st">&#39;num_boost_round&#39;</span>: <span class="dv">80</span> ,<span class="st">&#39;num_leaves&#39;</span>: ag.space.Int(lower<span class="op">=</span><span class="dv">26</span>, upper<span class="op">=</span><span class="dv">66</span>, default<span class="op">=</span><span class="dv">36</span>),}</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>hyperparameters <span class="op">=</span> {<span class="st">&#39;GBM&#39;</span>: gbm_options,<span class="st">&#39;NN&#39;</span>: nn_options, }  </span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>num_trials <span class="op">=</span> <span class="dv">3</span>  </span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>search_strategy <span class="op">=</span> <span class="st">&#39;auto&#39;</span></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>hyperparameter_tune_kwargs <span class="op">=</span> { </span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;num_trials&#39;</span>: num_trials,</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;scheduler&#39;</span> : <span class="st">&#39;local&#39;</span>,</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;searcher&#39;</span>: search_strategy,</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="52" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000,&quot;referenced_widgets&quot;:[&quot;ae0aa6a6b948424ea3da948ac12f3dd3&quot;,&quot;05ce9677e0fa474eb9759d0e9e8ef625&quot;,&quot;cebee1b0a77042f1a0bf019aa27ccb2c&quot;,&quot;8d5d481778894da9b6a93cf686b9f705&quot;,&quot;75d007d3403c450d8916cb1606bdd562&quot;,&quot;fdf59c34a2824354bed17a0284b1f108&quot;,&quot;88263ba37bac4605a5d107640efa5458&quot;,&quot;e8526d0b89044318961c204385793afe&quot;,&quot;8d4b418d7b9a4b92abbef7be539396dc&quot;,&quot;dc5299899d044954a69bbdc76f26e91b&quot;,&quot;3c294093b1c54625a28ab06e63eb9a75&quot;,&quot;a8ab58097d4c4255a8f7402392706ff1&quot;,&quot;4936a51beb194977af95f42f75a2a0dc&quot;,&quot;3cd56e31dadc442dafec7981f225f416&quot;,&quot;0cf769921f9b4336b87701665e09cd0d&quot;,&quot;ddad7823c251462e905d756966a0ab97&quot;,&quot;0bd1b2284da640cbb8eadfe93c5d86b4&quot;,&quot;683c77b602a8452593580fd90237b3a6&quot;,&quot;fd2a848fd4b249b997f8e7621be89b4e&quot;,&quot;bc7d48efb11246d480d84cb510d46b79&quot;,&quot;7cee0a360e4945e48fbf055f543298e5&quot;,&quot;e110f9c7287b4da39db4db7719cfc84c&quot;,&quot;eeb2585a5f4843d6a6133040cc403a82&quot;,&quot;a4d01b3907c341f29ff3947be7d33492&quot;,&quot;a459076f130a4bd595ad59cd42661ed8&quot;,&quot;2a73acf796d249acac451560ffe3d6d2&quot;,&quot;80b2206814c840b79d3994d2ee908441&quot;,&quot;762c8b62e0a24dfbbd52056b2dee42b6&quot;,&quot;5d0a43ca50224edaaf8744428a3c0433&quot;,&quot;7f09067dd7fe4c2ea4e7694af354294e&quot;,&quot;b284d87aca4949d99b77848a72722a2b&quot;,&quot;bba52b32bb4e4801a151f3a9975ddbce&quot;,&quot;d54199a6b9944a38867ea441625e5488&quot;,&quot;35d74296127b4c5baa46d6fa8040ee6c&quot;,&quot;9b3354e14e7a4adab76a1ba8134a549a&quot;,&quot;c08be8dee0444f8b8035c355fcfd1805&quot;,&quot;57575c8c5a5148f18edd44b5f9710c74&quot;,&quot;77c02c12c2214d1b915aa840cb012e47&quot;,&quot;955eddc75de04de3ae5ae36bfe228a92&quot;,&quot;560a9011e23d42f4afd886cb48907c80&quot;,&quot;185ef6ac64fe4665962acd76bbeaaffd&quot;,&quot;7fc4b2ace0ff434cb0a83696c43ca1ac&quot;,&quot;27d6c9dafe88400bbdb5598c9abe16c6&quot;,&quot;406149f63655493097588568ad38ea8b&quot;]}" id="XEc-g92T3RLI" data-outputId="e562568a-6a67-4910-9535-800ce630b6e8">
<div class="sourceCode" id="cb59"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo <span class="op">=</span> TabularPredictor(label <span class="op">=</span> <span class="st">&#39;count&#39;</span>,eval_metric <span class="op">=</span> <span class="st">&#39;root_mean_squared_error&#39;</span>, problem_type<span class="op">=</span><span class="st">&#39;regression&#39;</span>).fit(train, hyperparameters <span class="op">=</span> hyperparameters,  hyperparameter_tune_kwargs<span class="op">=</span> hyperparameter_tune_kwargs, presets<span class="op">=</span><span class="st">&#39;best_quality&#39;</span>, time_limit <span class="op">=</span> <span class="dv">600</span>)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>No path specified. Models will be saved in: &quot;AutogluonModels/ag-20230526_181958/&quot;
Presets specified: [&#39;best_quality&#39;]
Warning: hyperparameter tuning is currently experimental and may cause the process to hang.
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20
Beginning AutoGluon training ... Time limit = 600s
AutoGluon will save models to &quot;AutogluonModels/ag-20230526_181958/&quot;
AutoGluon Version:  0.7.0
Python Version:     3.10.11
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP Sat Apr 29 09:15:28 UTC 2023
Train Data Rows:    10886
Train Data Columns: 12
Label Column: count
Preprocessing data ...
Using Feature Generators to preprocess the data ...
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    10598.65 MB
	Train Data (Original)  Memory Usage: 0.89 MB (0.0% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
			Note: Converting 2 features to boolean dtype as they only contain 2 unique values.
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
		Fitting CategoryFeatureGenerator...
			Fitting CategoryMemoryMinimizeFeatureGenerator...
		Fitting DatetimeFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;category&#39;, []) : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;datetime&#39;, []) : 1 | [&#39;datetime&#39;]
		(&#39;float&#39;, [])    : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])      : 6 | [&#39;holiday&#39;, &#39;workingday&#39;, &#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, ...]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
		(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
		(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
		(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
		(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
	0.3s = Fit runtime
	12 features in original data used to generate 16 features in processed data.
	Train Data (Processed) Memory Usage: 1.09 MB (0.0% of available memory)
Data preprocessing and feature engineering runtime = 0.39s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;root_mean_squared_error&#39;
	This metric&#39;s sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	To change this, specify the eval_metric parameter of Predictor()
AutoGluon will fit 2 stack levels (L1 to L2) ...
	WARNING: &quot;NN&quot; model has been deprecated in v0.4.0 and renamed to &quot;NN_MXNET&quot;. Starting in v0.6.0, specifying &quot;NN&quot; or &quot;NN_MXNET&quot; will raise an exception. Consider instead specifying &quot;NN_TORCH&quot;.
Fitting 2 L1 models ...
Hyperparameter tuning model: LightGBM_BAG_L1 ... Tuning model for up to 179.84s of the 599.6s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb61"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;ae0aa6a6b948424ea3da948ac12f3dd3&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
Fitted model: LightGBM_BAG_L1/T1 ...
	-42.8501	 = Validation score   (-root_mean_squared_error)
	26.02s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T2 ...
	-40.2169	 = Validation score   (-root_mean_squared_error)
	26.54s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L1/T3 ...
	-40.2962	 = Validation score   (-root_mean_squared_error)
	25.97s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetMXNet_BAG_L1 ... Tuning model for up to 179.84s of the 520.92s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb63"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;a8ab58097d4c4255a8f7402392706ff1&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=20448, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=20448, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-26 18:21:24,490	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): ray::_ray_fit() (pid=20447, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=20543, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=20543, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
2023-05-26 18:21:33,305	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=20651, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=20651, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L1... Skipping this model.
Repeating k-fold bagging: 2/20
Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 299.16s of the 499.13s of remaining time.
	Fitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-26 18:21:39,605	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
	-42.3969	 = Validation score   (-root_mean_squared_error)
	48.34s	 = Training   runtime
	0.14s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 273.6s of the 473.56s of remaining time.
	Fitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy
	-39.7211	 = Validation score   (-root_mean_squared_error)
	50.62s	 = Training   runtime
	0.13s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T3 ... Training model for up to 246.11s of the 446.07s of remaining time.
	Fitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy
	-39.907	 = Validation score   (-root_mean_squared_error)
	55.9s	 = Training   runtime
	0.22s	 = Validation runtime
Repeating k-fold bagging: 3/20
Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 210.51s of the 410.47s of remaining time.
	Fitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy
	-42.2511	 = Validation score   (-root_mean_squared_error)
	70.74s	 = Training   runtime
	0.3s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 182.85s of the 382.82s of remaining time.
	Fitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy
	-39.6649	 = Validation score   (-root_mean_squared_error)
	73.01s	 = Training   runtime
	0.26s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T3 ... Training model for up to 156.82s of the 356.79s of remaining time.
	Fitting 8 child models (S3F1 - S3F8) | Fitting with ParallelLocalFoldFittingStrategy
	-39.7283	 = Validation score   (-root_mean_squared_error)
	78.73s	 = Training   runtime
	0.65s	 = Validation runtime
Repeating k-fold bagging: 4/20
Fitting model: LightGBM_BAG_L1/T1 ... Training model for up to 130.31s of the 330.27s of remaining time.
	Fitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy
	-42.1858	 = Validation score   (-root_mean_squared_error)
	93.4s	 = Training   runtime
	0.49s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T2 ... Training model for up to 104.13s of the 304.09s of remaining time.
	Fitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy
	-39.6421	 = Validation score   (-root_mean_squared_error)
	94.36s	 = Training   runtime
	0.43s	 = Validation runtime
Fitting model: LightGBM_BAG_L1/T3 ... Training model for up to 77.67s of the 277.63s of remaining time.
	Fitting 8 child models (S4F1 - S4F8) | Fitting with ParallelLocalFoldFittingStrategy
	-39.647	 = Validation score   (-root_mean_squared_error)
	100.73s	 = Training   runtime
	0.82s	 = Validation runtime
Completed 4/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 249.23s of remaining time.
	-39.1827	 = Validation score   (-root_mean_squared_error)
	0.3s	 = Training   runtime
	0.0s	 = Validation runtime
	WARNING: &quot;NN&quot; model has been deprecated in v0.4.0 and renamed to &quot;NN_MXNET&quot;. Starting in v0.6.0, specifying &quot;NN&quot; or &quot;NN_MXNET&quot; will raise an exception. Consider instead specifying &quot;NN_TORCH&quot;.
Fitting 2 L2 models ...
Hyperparameter tuning model: LightGBM_BAG_L2 ... Tuning model for up to 112.01s of the 248.9s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb65"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;eeb2585a5f4843d6a6133040cc403a82&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
	Stopping HPO to satisfy time limit...
Fitted model: LightGBM_BAG_L2/T1 ...
	-37.6791	 = Validation score   (-root_mean_squared_error)
	28.55s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L2/T2 ...
	-37.3315	 = Validation score   (-root_mean_squared_error)
	30.75s	 = Training   runtime
	0.0s	 = Validation runtime
Fitted model: LightGBM_BAG_L2/T3 ...
	-37.4582	 = Validation score   (-root_mean_squared_error)
	26.31s	 = Training   runtime
	0.0s	 = Validation runtime
Hyperparameter tuning model: NeuralNetMXNet_BAG_L2 ... Tuning model for up to 112.01s of the 163.16s of remaining time.
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb67"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;35d74296127b4c5baa46d6fa8040ee6c&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
ray::_ray_fit() (pid=25267, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=25267, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-26 18:27:23,531	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=25372, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=25372, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
	Fitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy
2023-05-26 18:27:32,529	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
ray::_ray_fit() (pid=25504, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
Traceback (most recent call last):
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 43, in model_trial
    model = fit_and_save_model(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/model_trial.py&quot;, line 101, in fit_and_save_model
    model.fit(**fit_args, time_limit=time_left)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py&quot;, line 154, in _fit
    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 248, in _fit
    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py&quot;, line 540, in _fit_folds
    fold_fitting_strategy.after_all_folds_scheduled()
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 537, in after_all_folds_scheduled
    raise processed_exception
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 505, in after_all_folds_scheduled
    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py&quot;, line 105, in wrapper
    return func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py&quot;, line 2309, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): ray::_ray_fit() (pid=25504, ip=172.28.0.12)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py&quot;, line 374, in _ray_fit
    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold,
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py&quot;, line 703, in fit
    out = self._fit(**kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 156, in _fit
    train_dataset, val_dataset = self.generate_datasets(X=X, y=y, params=params, X_val=X_val, y_val=y_val)
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 446, in generate_datasets
    train_dataset = self.process_train_data(
  File &quot;/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/tabular_nn/mxnet/tabular_nn_mxnet.py&quot;, line 511, in process_train_data
    df = self.processor.fit_transform(df) # 2D numpy array
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 727, in fit_transform
    result = self._fit_transform(X, y, _fit_transform_one)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py&quot;, line 658, in _fit_transform
    return Parallel(n_jobs=self.n_jobs)(
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 63, in __call__
    return super().__call__(iterable_with_config)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 1088, in __call__
    while self.dispatch_one_batch(iterator):
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 901, in dispatch_one_batch
    self._dispatch(tasks)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 819, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 208, in apply_async
    result = ImmediateResult(func)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py&quot;, line 597, in __init__
    self.results = batch()
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in __call__
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/parallel.py&quot;, line 288, in &lt;listcomp&gt;
    return [func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py&quot;, line 123, in __call__
    return self.function(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 437, in fit_transform
    Xt = self._fit(X, y, **fit_params_steps)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 359, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File &quot;/usr/local/lib/python3.10/dist-packages/joblib/memory.py&quot;, line 349, in __call__
    return self.func(*args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py&quot;, line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py&quot;, line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/base.py&quot;, line 878, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File &quot;/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py&quot;, line 408, in fit
    raise ValueError(
ValueError: &#39;fill_value&#39;=!missing! is invalid. Expected a numerical value when imputing numerical data
No model was trained during hyperparameter tuning NeuralNetMXNet_BAG_L2... Skipping this model.
Completed 1/20 k-fold bagging repeats ...
Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 141.51s of remaining time.
	-37.1828	 = Validation score   (-root_mean_squared_error)
	0.36s	 = Training   runtime
	0.0s	 = Validation runtime
AutoGluon training complete, total runtime = 458.9s ... Best model: &quot;WeightedEnsemble_L3&quot;
TabularPredictor saved. To load, use: predictor = TabularPredictor.load(&quot;AutogluonModels/ag-20230526_181958/&quot;)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="53" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="CT9lA92v3RLJ" data-outputId="0596c38e-13d1-4dc2-fa60-35714c1184a7">
<div class="sourceCode" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>predictor_new_hpo.fit_summary()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>2023-05-26 18:27:37,598	ERROR worker.py:400 -- Unhandled error (suppress with &#39;RAY_IGNORE_UNHANDLED_ERRORS=1&#39;): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>*** Summary of fit() ***
Estimated performance of each model:
                 model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
0  WeightedEnsemble_L3 -37.182771       1.733366  345.896416                0.000968           0.359208            3       True          8
1   LightGBM_BAG_L2/T2 -37.331507       1.732252  319.229586                0.000125          30.745506            2       True          6
2   LightGBM_BAG_L2/T3 -37.458189       1.732273  314.791703                0.000146          26.307622            2       True          7
3   LightGBM_BAG_L2/T1 -37.679079       1.732253  317.035161                0.000127          28.551080            2       True          5
4  WeightedEnsemble_L2 -39.182668       1.244764  195.383534                0.000877           0.296068            2       True          4
5   LightGBM_BAG_L1/T2 -39.642104       0.425419   94.361245                0.425419          94.361245            1       True          2
6   LightGBM_BAG_L1/T3 -39.647040       0.818469  100.726221                0.818469         100.726221            1       True          3
7   LightGBM_BAG_L1/T1 -42.185831       0.488240   93.396614                0.488240          93.396614            1       True          1
Number of models trained: 8
Types of models trained:
{&#39;StackerEnsembleModel_LGB&#39;, &#39;WeightedEnsembleModel&#39;}
Bagging used: True  (with 8 folds)
Multi-layer stack-ensembling used: True  (with 3 levels)
Feature Metadata (Processed):
(raw dtype, special dtypes):
(&#39;category&#39;, [])             : 2 | [&#39;season&#39;, &#39;weather&#39;]
(&#39;float&#39;, [])                : 3 | [&#39;temp&#39;, &#39;atemp&#39;, &#39;windspeed&#39;]
(&#39;int&#39;, [])                  : 4 | [&#39;humidity&#39;, &#39;month&#39;, &#39;day&#39;, &#39;hour&#39;]
(&#39;int&#39;, [&#39;bool&#39;])            : 2 | [&#39;holiday&#39;, &#39;workingday&#39;]
(&#39;int&#39;, [&#39;datetime_as_int&#39;]) : 5 | [&#39;datetime&#39;, &#39;datetime.year&#39;, &#39;datetime.month&#39;, &#39;datetime.day&#39;, &#39;datetime.dayofweek&#39;]
*** End of fit() summary ***
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;
  warnings.warn(&#39;AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: &quot;pip install bokeh==2.0.1&quot;&#39;)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="53">
<pre><code>{&#39;model_types&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L1/T3&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;WeightedEnsembleModel&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;LightGBM_BAG_L2/T3&#39;: &#39;StackerEnsembleModel_LGB&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;WeightedEnsembleModel&#39;},
 &#39;model_performance&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: -42.18583096259412,
  &#39;LightGBM_BAG_L1/T2&#39;: -39.64210391335984,
  &#39;LightGBM_BAG_L1/T3&#39;: -39.647040038304375,
  &#39;WeightedEnsemble_L2&#39;: -39.18266761691087,
  &#39;LightGBM_BAG_L2/T1&#39;: -37.679079102884074,
  &#39;LightGBM_BAG_L2/T2&#39;: -37.33150706475182,
  &#39;LightGBM_BAG_L2/T3&#39;: -37.458188912094464,
  &#39;WeightedEnsemble_L3&#39;: -37.1827711895674},
 &#39;model_best&#39;: &#39;WeightedEnsemble_L3&#39;,
 &#39;model_paths&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: &#39;/content/AutogluonModels/ag-20230526_181958/models/LightGBM_BAG_L1/T1/&#39;,
  &#39;LightGBM_BAG_L1/T2&#39;: &#39;/content/AutogluonModels/ag-20230526_181958/models/LightGBM_BAG_L1/T2/&#39;,
  &#39;LightGBM_BAG_L1/T3&#39;: &#39;/content/AutogluonModels/ag-20230526_181958/models/LightGBM_BAG_L1/T3/&#39;,
  &#39;WeightedEnsemble_L2&#39;: &#39;AutogluonModels/ag-20230526_181958/models/WeightedEnsemble_L2/&#39;,
  &#39;LightGBM_BAG_L2/T1&#39;: &#39;/content/AutogluonModels/ag-20230526_181958/models/LightGBM_BAG_L2/T1/&#39;,
  &#39;LightGBM_BAG_L2/T2&#39;: &#39;/content/AutogluonModels/ag-20230526_181958/models/LightGBM_BAG_L2/T2/&#39;,
  &#39;LightGBM_BAG_L2/T3&#39;: &#39;/content/AutogluonModels/ag-20230526_181958/models/LightGBM_BAG_L2/T3/&#39;,
  &#39;WeightedEnsemble_L3&#39;: &#39;AutogluonModels/ag-20230526_181958/models/WeightedEnsemble_L3/&#39;},
 &#39;model_fit_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 93.39661383628845,
  &#39;LightGBM_BAG_L1/T2&#39;: 94.36124515533447,
  &#39;LightGBM_BAG_L1/T3&#39;: 100.7262213230133,
  &#39;WeightedEnsemble_L2&#39;: 0.2960679531097412,
  &#39;LightGBM_BAG_L2/T1&#39;: 28.551080465316772,
  &#39;LightGBM_BAG_L2/T2&#39;: 30.745505571365356,
  &#39;LightGBM_BAG_L2/T3&#39;: 26.30762219429016,
  &#39;WeightedEnsemble_L3&#39;: 0.359208345413208},
 &#39;model_pred_times&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: 0.4882395267486572,
  &#39;LightGBM_BAG_L1/T2&#39;: 0.4254186153411865,
  &#39;LightGBM_BAG_L1/T3&#39;: 0.8184685707092285,
  &#39;WeightedEnsemble_L2&#39;: 0.0008769035339355469,
  &#39;LightGBM_BAG_L2/T1&#39;: 0.0001266002655029297,
  &#39;LightGBM_BAG_L2/T2&#39;: 0.00012493133544921875,
  &#39;LightGBM_BAG_L2/T3&#39;: 0.00014638900756835938,
  &#39;WeightedEnsemble_L3&#39;: 0.0009679794311523438},
 &#39;num_bag_folds&#39;: 8,
 &#39;max_stack_level&#39;: 3,
 &#39;model_hyperparams&#39;: {&#39;LightGBM_BAG_L1/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L1/T3&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L2&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T1&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T2&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;LightGBM_BAG_L2/T3&#39;: {&#39;use_orig_features&#39;: True,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True},
  &#39;WeightedEnsemble_L3&#39;: {&#39;use_orig_features&#39;: False,
   &#39;max_base_models&#39;: 25,
   &#39;max_base_models_per_type&#39;: 5,
   &#39;save_bag_folds&#39;: True}},
 &#39;leaderboard&#39;:                  model  score_val  pred_time_val    fit_time  \
 0  WeightedEnsemble_L3 -37.182771       1.733366  345.896416   
 1   LightGBM_BAG_L2/T2 -37.331507       1.732252  319.229586   
 2   LightGBM_BAG_L2/T3 -37.458189       1.732273  314.791703   
 3   LightGBM_BAG_L2/T1 -37.679079       1.732253  317.035161   
 4  WeightedEnsemble_L2 -39.182668       1.244764  195.383534   
 5   LightGBM_BAG_L1/T2 -39.642104       0.425419   94.361245   
 6   LightGBM_BAG_L1/T3 -39.647040       0.818469  100.726221   
 7   LightGBM_BAG_L1/T1 -42.185831       0.488240   93.396614   
 
    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \
 0                0.000968           0.359208            3       True   
 1                0.000125          30.745506            2       True   
 2                0.000146          26.307622            2       True   
 3                0.000127          28.551080            2       True   
 4                0.000877           0.296068            2       True   
 5                0.425419          94.361245            1       True   
 6                0.818469         100.726221            1       True   
 7                0.488240          93.396614            1       True   
 
    fit_order  
 0          8  
 1          6  
 2          7  
 3          5  
 4          4  
 5          2  
 6          3  
 7          1  }</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="54" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="R52EOpc43RLJ" data-outputId="5c64737d-1ee4-4fa1-e585-a9de2c5033ff">
<div class="sourceCode" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember to set all negative values to zero</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>predictions_new_hpo <span class="op">=</span> predictor_new_hpo.predict(test)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>predictions_new_hpo[predictions_new_hpo <span class="op">&lt;</span> <span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>predictions_new_hpo</span></code></pre></div>
<div class="output execute_result" data-execution_count="54">
<pre><code>0        13.806871
1         7.927480
2         7.927480
3         7.931304
4         7.931304
           ...    
6488    354.979126
6489    238.640808
6490    172.561218
6491    120.075745
6492     79.039230
Name: count, Length: 6493, dtype: float32</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="55" id="V34qJ01q3RLK">
<div class="sourceCode" id="cb76"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Same submitting predictions</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>submission_new_hpo <span class="op">=</span> submission</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>submission_new_hpo[<span class="st">&quot;count&quot;</span>] <span class="op">=</span> predictions_new_hpo</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>submission_new_hpo.to_csv(<span class="st">&quot;submission_new_hpo.csv&quot;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="56" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="BRQeotNp3RLL" data-outputId="bc9a7ef0-3caa-42da-8c1e-21772bfc7629">
<div class="sourceCode" id="cb77"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submit <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">-</span>f submission_new_hpo.csv <span class="op">-</span>m <span class="st">&quot;new features with hyperparameters&quot;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>100% 188k/188k [00:02&lt;00:00, 68.2kB/s]
Successfully submitted to Bike Sharing Demand</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="57" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="tinYMiio3RLL" data-outputId="de8d6bc4-8181-4d8a-a8a9-90eee5d9cbc9">
<div class="sourceCode" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>kaggle competitions submissions <span class="op">-</span>c bike<span class="op">-</span>sharing<span class="op">-</span>demand <span class="op">|</span> tail <span class="op">-</span>n <span class="op">+</span><span class="dv">1</span> <span class="op">|</span> head <span class="op">-</span>n <span class="dv">6</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>fileName                     date                 description                        status    publicScore  privateScore  
---------------------------  -------------------  ---------------------------------  --------  -----------  ------------  
submission_new_hpo.csv       2023-05-26 18:27:46  new features with hyperparameters  complete  0.49818      0.49818       
submission_new_features.csv  2023-05-26 17:51:54  new features                       complete  0.62685      0.62685       
submission.csv               2023-05-26 17:37:48  first raw submission               complete  1.80114      1.80114       
submission_new_hpo.csv       2023-05-19 13:19:59  new features with hyperparameters  complete  0.61717      0.61717       
</code></pre>
</div>
</div>
<section id="new-score-of-049818" class="cell markdown" id="y0XfjFlq3RLM">
<h4>New Score of 0.49818</h4>
</section>
<section id="step-7-write-a-report" class="cell markdown" id="PSiyqGGV3RLM">
<h2>Step 7: Write a Report</h2>
<h3 id="refer-to-the-markdown-file-for-the-full-report">Refer to the markdown file for the full report</h3>
<h3 id="creating-plots-and-table-for-report">Creating plots and table for report</h3>
</section>
<div class="cell code" data-execution_count="58" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:542}" id="D1DvtFRg3RLM" data-jupyter="{&quot;source_hidden&quot;:true}" data-outputId="32b77c7f-f2e6-4d7d-f2a6-164fe7da6f6f">
<div class="sourceCode" id="cb81"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Taking the top model score from each training run and creating a line plot to show improvement</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="co"># You can create these in the notebook and save them to PNG or use some other tool (e.g. google sheets, excel)</span></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> pd.DataFrame(</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;model&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;score&quot;</span>: [<span class="fl">1.80114</span>, <span class="fl">0.62685</span>, <span class="fl">0.49818</span>]</span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>).plot(x<span class="op">=</span><span class="st">&quot;model&quot;</span>, y<span class="op">=</span><span class="st">&quot;score&quot;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>)).get_figure()</span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;model_train_score.png&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img src="128aae4c2b37d4afb876ccc10899193acddb2d42.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="59" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:542}" id="_TepIT1j3RLN" data-outputId="1c2bed9e-8981-4c7a-a66a-e773b61da07c">
<div class="sourceCode" id="cb82"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Take the 3 kaggle scores and creating a line plot to show improvement</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> pd.DataFrame(</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;test_eval&quot;</span>: [<span class="st">&quot;initial&quot;</span>, <span class="st">&quot;add_features&quot;</span>, <span class="st">&quot;hpo&quot;</span>],</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;score&quot;</span>: [<span class="fl">1.80114</span>, <span class="fl">0.62685</span>, <span class="fl">0.49818</span>]</span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>).plot(x<span class="op">=</span><span class="st">&quot;test_eval&quot;</span>, y<span class="op">=</span><span class="st">&quot;score&quot;</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>)).get_figure()</span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>fig.savefig(<span class="st">&#39;model_test_score.png&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img src="249435470c5dee15c011bf1b3b106288394e86d0.png" /></p>
</div>
</div>
<section id="hyperparameter-table" class="cell markdown" id="F_Y0aOTY3RLN">
<h3>Hyperparameter table</h3>
</section>
<div class="cell code" data-execution_count="60" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:143}" id="wbhhoexS3RLO" data-outputId="371c8abc-35a1-4ee4-a477-d0b43417ec22">
<div class="sourceCode" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The 3 hyperparameters we tuned with the kaggle score as the result</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a> <span class="st">&quot;model&quot;</span>: [<span class="st">&quot;initial_model&quot;</span>, <span class="st">&quot;add_features_model&quot;</span>, <span class="st">&quot;hpo_model&quot;</span>],</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo1&quot;</span>: [<span class="st">&#39;default_vals&#39;</span>, <span class="st">&#39;default_vals&#39;</span>, <span class="st">&#39;GBM: num_leaves: lower=26, upper=66&#39;</span>],</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo2&quot;</span>: [<span class="st">&#39;default_vals&#39;</span>, <span class="st">&#39;default_vals&#39;</span>, <span class="st">&#39;NN: dropout_prob: 0.0, 0.5&#39;</span>],</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;hpo3&quot;</span>: [<span class="st">&#39;default_vals&#39;</span>, <span class="st">&#39;default_vals&#39;</span>, <span class="st">&#39;GBM: num_boost_round: 100&#39;</span>],</span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;score&quot;</span>: [<span class="fl">1.39920</span>,  <span class="fl">0.47165</span>, <span class="fl">0.50893</span>]</span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>})</span></code></pre></div>
<div class="output execute_result" data-execution_count="60">

  <div id="df-fd4bcd04-7165-47dd-93cc-cb7e1708f6f9">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>hpo1</th>
      <th>hpo2</th>
      <th>hpo3</th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>initial_model</td>
      <td>default_vals</td>
      <td>default_vals</td>
      <td>default_vals</td>
      <td>1.39920</td>
    </tr>
    <tr>
      <th>1</th>
      <td>add_features_model</td>
      <td>default_vals</td>
      <td>default_vals</td>
      <td>default_vals</td>
      <td>0.47165</td>
    </tr>
    <tr>
      <th>2</th>
      <td>hpo_model</td>
      <td>GBM: num_leaves: lower=26, upper=66</td>
      <td>NN: dropout_prob: 0.0, 0.5</td>
      <td>GBM: num_boost_round: 100</td>
      <td>0.50893</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-fd4bcd04-7165-47dd-93cc-cb7e1708f6f9')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-fd4bcd04-7165-47dd-93cc-cb7e1708f6f9 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-fd4bcd04-7165-47dd-93cc-cb7e1708f6f9');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>
</div>
</body>
</html>
